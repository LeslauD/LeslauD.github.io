<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.99.1" />
    <meta name="description" content="">


    <link rel="shortcut icon" href="/images/favicon.png" type="image/x-icon" />

    <title>LinearRegression :: 刘顿的博客</title>

    
    <link href="/css/nucleus.css?1659541637" rel="stylesheet">
    <link href="/css/fontawesome-all.min.css?1659541637" rel="stylesheet">
    <link href="/css/hybrid.css?1659541637" rel="stylesheet">
    <link href="/css/featherlight.min.css?1659541637" rel="stylesheet">
    <link href="/css/perfect-scrollbar.min.css?1659541637" rel="stylesheet">
    <link href="/css/auto-complete.css?1659541637" rel="stylesheet">
    <link href="/css/atom-one-dark-reasonable.css?1659541637" rel="stylesheet">
    <link href="/css/theme.css?1659541637" rel="stylesheet">
    <link href="/css/tabs.css?1659541637" rel="stylesheet">
    <link href="/css/hugo-theme.css?1659541637" rel="stylesheet">
    
    <link href="/css/theme-blue.css?1659541637" rel="stylesheet">
    
    

    <script src="/js/jquery-3.3.1.min.js?1659541637"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
    </style>
    
  </head>
  <body class="" data-url="/machinelearning/linearregression/">
    <nav id="sidebar" class="">



  <div id="header-wrapper">
    <div id="header">
      <img src="/images/keeprush.png">

    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="/js/lunr.min.js?1659541637"></script>
<script type="text/javascript" src="/js/auto-complete.js?1659541637"></script>
<script type="text/javascript">
    
        var baseurl = "http:\/\/example.org\/";
    
</script>
<script type="text/javascript" src="/js/search.js?1659541637"></script>

    
  </div>
  
    <section id="homelinks">
      <ul>
        <li>
            <a class="padding" href='/'><i class='fas fa-home'></i> Home</a>
        </li>
      </ul>
    </section>
  

    <div class="highlightable">
    <ul class="topics">

        
          
          




 
  
    
    <li data-nav-id="/resume/" title="个人简历" class="dd-item
        
        
        
        ">
      <a href="/resume/">
          <b></b>个人简历
          
      </a>
      
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/photograph/" title="摄影" class="dd-item
        
        
        
        ">
      <a href="/photograph/">
          <b></b>摄影
          
      </a>
      
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/algorithm/" title="数据结构与算法" class="dd-item
        
        
        
        ">
      <a href="/algorithm/">
          <b></b>数据结构与算法
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/algorithm/leetcode/" title="LeetCode" class="dd-item
        
        
        
        ">
      <a href="/algorithm/leetcode/">
          LeetCode
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/algorithm/newcoder/" title="NewCoder" class="dd-item
        
        
        
        ">
      <a href="/algorithm/newcoder/">
          NewCoder
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/algorithm/pat/" title="PAT" class="dd-item
        
        
        
        ">
      <a href="/algorithm/pat/">
          PAT
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/algorithm/tooffer/" title="剑指Offer" class="dd-item
        
        
        
        ">
      <a href="/algorithm/tooffer/">
          剑指Offer
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/algorithm/datastruct/" title="数据结构" class="dd-item
        
        
        
        ">
      <a href="/algorithm/datastruct/">
          数据结构
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/machinelearning/" title="机器学习" class="dd-item
        parent
        
        
        ">
      <a href="/machinelearning/">
          <b></b>机器学习
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/machinelearning/linearclassfication/" title="LinearClassification" class="dd-item
        
        
        
        ">
      <a href="/machinelearning/linearclassfication/">
          LinearClassification
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/machinelearning/linearregression/" title="LinearRegression" class="dd-item
        parent
        active
        
        ">
      <a href="/machinelearning/linearregression/">
          LinearRegression
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/machinelearning/recommendedsystem/" title="RecommendedSystem" class="dd-item
        
        
        
        ">
      <a href="/machinelearning/recommendedsystem/">
          RecommendedSystem
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/deeplearning/" title="深度学习" class="dd-item
        
        
        
        ">
      <a href="/deeplearning/">
          <b></b>深度学习
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/deeplearning/tensorflow/" title="TensorFlow" class="dd-item
        
        
        
        ">
      <a href="/deeplearning/tensorflow/">
          TensorFlow
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/deeplearning/basic/" title="基础算法理论" class="dd-item
        
        
        
        ">
      <a href="/deeplearning/basic/">
          基础算法理论
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/vehicle/" title="车车" class="dd-item
        
        
        
        ">
      <a href="/vehicle/">
          <b></b>车车
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/vehicle/santana/" title="1:18 Santana" class="dd-item
        
        
        
        ">
      <a href="/vehicle/santana/">
          1:18 Santana
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/piano/" title="钢琴" class="dd-item
        
        
        
        ">
      <a href="/piano/">
          <b></b>钢琴
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/piano/summer/" title="summer" class="dd-item
        
        
        
        ">
      <a href="/piano/summer/">
          <b></b>summer
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/piano/cannon/" title="卡农" class="dd-item
        
        
        
        ">
      <a href="/piano/cannon/">
          <b></b>卡农
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/piano/basic/" title="基本乐理" class="dd-item
        
        
        
        ">
      <a href="/piano/basic/">
          <b></b>基本乐理
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/piano/sunrise/" title="太阳照常升起" class="dd-item
        
        
        
        ">
      <a href="/piano/sunrise/">
          <b></b>太阳照常升起
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/piano/littlestar/" title="小星星变奏曲" class="dd-item
        
        
        
        ">
      <a href="/piano/littlestar/">
          <b></b>小星星变奏曲
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/programs/" title="项目" class="dd-item
        
        
        
        ">
      <a href="/programs/">
          <b></b>项目
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/programs/bodyassessment/" title="BodyAssessment" class="dd-item
        
        
        
        ">
      <a href="/programs/bodyassessment/">
          <b></b>BodyAssessment
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/programs/bodyassessment/imageprocess/" title="ImageProcess" class="dd-item
        
        
        
        ">
      <a href="/programs/bodyassessment/imageprocess/">
          ImageProcess
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/programs/joyyourmind/" title="JoyYourMind" class="dd-item
        
        
        
        ">
      <a href="/programs/joyyourmind/">
          <b></b>JoyYourMind
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/programs/millenniumtemple/" title="MillenniumTemple" class="dd-item
        
        
        
        ">
      <a href="/programs/millenniumtemple/">
          <b></b>MillenniumTemple
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/cxx/" title="CPP" class="dd-item
        
        
        
        ">
      <a href="/cxx/">
          <b></b>CPP
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/cxx/clang/" title="C language" class="dd-item
        
        
        
        ">
      <a href="/cxx/clang/">
          C language
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/cxx/cpp/" title="CPP" class="dd-item
        
        
        
        ">
      <a href="/cxx/cpp/">
          CPP
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/bigdata/" title="大数据" class="dd-item
        
        
        
        ">
      <a href="/bigdata/">
          <b></b>大数据
          
      </a>
      
      
        <ul>
          
          
            
          
          

        
          
            
            




 
  
    
    <li data-nav-id="/bigdata/hadoop/" title="Hadoop" class="dd-item
        
        
        
        ">
      <a href="/bigdata/hadoop/">
          Hadoop
          
      </a>
      
      
    </li>
  
 

            
          
            
            




 
  
    
    <li data-nav-id="/bigdata/spark/" title="Spark" class="dd-item
        
        
        
        ">
      <a href="/bigdata/spark/">
          Spark
          
      </a>
      
      
    </li>
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
        
    </ul>

    
    

    
    <section id="footer">
      <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fas fa-heart"></i></a> from <a href="https://getgrav.org">Grav</a> and <a href="https://gohugo.io/">Hugo</a></p>

    </section>
  </div>
</nav>




        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                    
          
          
            
            
          
          
            
            
          
          
            <a href='/'></a> > <a href='/machinelearning/'>机器学习</a> > LinearRegression
          
        
          
        
          
        
                 
                  </span>
                </div>
                
                    <div class="progress">
    <div class="wrapper">
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#线性回归算法">线性回归算法</a></li>
        <li><a href="#深入线性回归算法的推导">深入线性回归算法的推导</a></li>
        <li><a href="#解析解方法求解线性回归">解析解方法求解线性回归</a></li>
        <li><a href="#梯度下降">梯度下降</a></li>
        <li><a href="#三种梯度下降法">三种梯度下降法</a></li>
        <li><a href="#归一化-normalization">归一化 normalization</a></li>
        <li><a href="#正则化">正则化</a></li>
        <li><a href="#多项式升维">多项式升维</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              LinearRegression
            </h1>
          

        



	<h3 id="线性回归算法">线性回归算法</h3>
<p>回归问题主要关注确定一个唯一的因变量(dependent variable)(需要预测的值)和一个或多个数值型的自变量(independent variables)(预测变量)之间的关系</p>
<p>需要预测的值：即目标变量，target，y，连续值</p>
<p>预测变量：影响目标变量的因素，predictors，X1&hellip;Xn，</p>
<p>可以是连续值也可以是离散值之间的关系：即模型，model，是我们要求解的</p>
<br>
<h4 id="连续值和离散值">连续值和离散值</h4>
<img src="\images\discrete_continue.png">
<br>
<h4 id="简单线性回归">简单线性回归</h4>
<p>$$
y=a+bx
$$</p>
<p>公式中的参数a,b及为要求得的模型</p>
<br>
<h4 id="最优解">最优解</h4>
<p>真实值 y_true: 已知的y</p>
<p>预测值 y_pred: 利用求出的a,b，将x代入模型求得的y_hat</p>
<p>误差 error: y_true和y_pred之间的距离</p>
<p>最优解：尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失 Loss</p>
<p>Loss：整体的误差，loss 通过损失函数 loss function 计算得到</p>
<br>
<h4 id="多元线性回归">多元线性回归</h4>
<p>简单线性回归中影响因素（特征）X只有一个</p>
<img src="\images\signal_lr.png">
<p>多元线性回归中，X有n个，即X1,X2,&hellip;,Xn</p>
<img src="\images\multi_lr.png">
<p>每一行对应一个样本，Y为真实结果，每一个样本有X1,X2,X3,&hellip;.共n列特征，为了计算模型的偏置项，设置X0为1，最后一列ε为误差error，β为每个特性x对应的权重w(weight)</p>
<p>即
$$
y = β_0+β_1X_1+β_2X_2+&hellip;+β_nX_n+ε
$$</p>
<p>$$
y = W^TX+ε<br>
$$</p>
<p>$$
y = XW+ε
$$</p>
<p><br><br></p>
<h3 id="深入线性回归算法的推导">深入线性回归算法的推导</h3>
<h4 id="中心极限定理">中心极限定理</h4>
<img src="\images\golden.png">
<p>在自然界与生产中，一些现象受到许多<strong>相互独立</strong>的<strong>随机因素</strong>的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。</p>
<p><strong>机器学习中，假设误差符合均值为0，方差为定值的正态分布</strong></p>
<br>
<h4 id="正态分布的线性回归的最大总似然">正态分布的线性回归的最大总似然</h4>
<p>一条样本的误差的概率密度函数可以表示如下：
$$
f(ε_i|μ,σ^2) = \frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(ε_i-0)^2}{2σ^2}}
$$
最大似然：发生的概率最大</p>
<p>把最大似然函数通过正太分布概率密度函数表达出来
$$
L_θ(ε1,&hellip;ε_m) = f(ε1,&hellip;ε_m|μ,σ^2)
$$
由于假设了误差服从正态分布，符合中心极限定理，也就是样本误差相互独立，所以：
$$
f(ε1,&hellip;ε_m|μ,σ^2) =  f(ε1|μ,σ^2)* f(ε2|μ,σ^2)<em>&hellip;</em> f(ε_m|μ,σ^2)
$$
所以
$$
L_θ(ε1,&hellip;ε_m) = Π_{i=1}^{m}f(ε_i|μ,σ^2) = Π_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(ε_i-0)^2}{2σ^2}}
$$
线性回归误差函数可以写为：
$$
ε_i = |y_i-\overline{y_i}| = |y_i - W^TX_i| = |y_i - θ^TX_i|
$$
最大似然估计如下：
$$
L_θ(ε1,&hellip;ε_m) = Π_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(ε_i-0)^2}{2σ^2}} = Π_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(y_i-θ^Tx_i)^2}{2σ^2}}
$$
<br></p>
<h4 id="推导出线性回归损失函数">推导出线性回归损失函数</h4>
<p>根据最大似然估计的思想，待求的参数θ就是似然函数L取得最大值时的θ，即
$$
argmax_θL_θ(ε1,&hellip;ε_m) = argmax_θΠ_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(y_i-θ^Tx_i)^2}{2σ^2}}
$$</p>
<h4 id="对数似然函数">对数似然函数</h4>
<p>为了方面计算，对上面的似然函数取e为底的对数
$$
argmax_θL_θ(ε1,&hellip;ε_m) = argmax_θlog_e{Π_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(y_i-θ^Tx_i)^2}{2σ^2}}}
$$
即损失函数
$$
l(θ) = argmax_θlog_e(Π_{i=1}^{m}\frac{1}{\sqrt{2Πσ^2}}e^{-\frac{(y_i-θ^Tx_i)^2}{2σ^2}})
\= \sum\limits_{i=1}^mlog\frac{1}{\sqrt{2Π}σ}exp(-\frac{(y^i-θ^Tx_i)^2}{2σ^2})
\= mlog\frac{1}{\sqrt{2Π}σ}-\frac{1}{2σ^2}\sum\limits_{i=1}^m(y^i-θ^Tx^i)^2
$$</p>
<p>$$
J(θ) = \frac{1}{2}\sum\limits_{i=1}^m(y^i-h_θ(x^i))^2
$$</p>
<p>最大化似然函数即为最小化J(θ)，也就是Mean Square Error</p>
<br>
<br>
<h3 id="解析解方法求解线性回归">解析解方法求解线性回归</h3>
<p>用矩阵表示损失函数
$$
J(θ) = \frac{1}{2}(Xθ-y)^T(Xθ-y)
\ = \frac{1}{2}(θ^TX^TXθ-θ^TX^Ty-y^TXθ+y^Ty)
$$
由于J(θ)是凸函数，驻点为0的点对应最有解，导函数：
$$
J^{/}(θ) = \frac{1}{2}[(θ^TX^TXθ)^/-(θ^TX^Ty)^/-(y^TXθ)^/+(y^Ty)^/]
\ = \frac{1}{2}[2X^TXθ-X^Ty-(y^TX)^T]
\ = X^TXθ-X^Ty
\ = 0
$$
解之得
$$
θ = (X^TX)^{-1}X^Ty
$$
<br></p>
<h4 id="凸函数非凸函数">凸函数、非凸函数</h4>
<img src="\images\convex.png">
<br>
<br>
<br>
<h3 id="梯度下降">梯度下降</h3>
<p>        之前利用θ的解析解公式求解出来的解我们就直接说是最优解的一个原因是因为 MSE 这个损失函数是凸函数，但是如果我们机器学习的损失函数是非凸函数的话，设置梯度为 0 会得到很多个极值，甚至是极大值都有可能。</p>
<p>        之前利用θ的解析解公式求解的另一个原因是特征维度并不多，但是细致分析一下公式 里面 X T X 对称阵是 N 维乘以 N 维的，复杂度是是 O(N)的三次方，换句话说，就是如果你 的特征数量翻倍，你的计算时间大致上要 2 的三次方，8 倍的慢</p>
<p>        所以其实之前一步求出最优解并不是机器学习甚至深度学习常用的手段，如下图，之前 我们是设置梯度为 0，反过来求解最低点的时候θ是多少，而梯度下降法是一点点去逼近最 优解！</p>
<h4 id="梯度下降法的思想">梯度下降法的思想</h4>
<img src="\images\gradient_descent.png">
<p>先随机初始化一个θ，代入模型计算损失，朝着损失函数的负梯度方向调整θ，知道损失尽可能小</p>
<h4 id="梯度下降法的公式">梯度下降法的公式</h4>
<p>$$
W_j^{t+1} = W_j^{t} - η*gradient_j
$$</p>
<p>其中η就是学习率，代表更新W的步长</p>
<p>学习率过小会导致收敛速度太慢，过大会产生震荡，难以收敛，如下图：</p>
<img src="\images\lr.png">
<p>学习率的设置是门学问，一般我们会把它设置成一个比较小的正整数，0.1、0.01、0.001、 0.0001，都是常见的设定数值，一般情况下学习率在整体迭代过程中是一直不变的数，但 是也可以设置成随着迭代次数增多学习率逐渐变小，因为越靠近山谷我们就可以步子迈小 点，省得走过，还有一些深度学习的优化算法会自己控制调整学习率这个值</p>
<img src="\images\lr2.png">
<h4 id="全局最优解">全局最优解</h4>
<img src="\images\global_minimum.png">
<p>上图可以看出如果损失函数是非凸函数，梯度下降法是有可能落到局部最小值的，所以其实 步长不能设置的太小太稳健，那样就很容易落入局部最优解，虽说局部最小值也没大问题， 因为模型只要是堪用的就好嘛，但是我们肯定还是尽量要奔着全局最优解去。</p>
<h4 id="梯度下降法流程">梯度下降法流程</h4>
<ol>
<li>瞎蒙，Random 随机θ，随机一组数值 W0…Wn</li>
<li>求梯度，为什么是梯度？因为梯度代表曲线某点上的切线的斜率，沿着切线往下下 降就相当于沿着坡度最陡峭的方向下降</li>
<li>if g&lt;0, theta 变大，if g&gt;0, theta 变小</li>
<li>判断是否收敛 convergence，如果收敛跳出迭代，如果没有达到收敛，回第 2 步继续</li>
</ol>
<ul>
<li>
<p>如何随机？</p>
<ul>
<li>np.random.rand()或者 np.random.randn()</li>
</ul>
</li>
<li>
<p>怎么求梯度？</p>
<ul>
<li>$$
gradient_j = \frac{\partial{Loss}}{W_j}
$$</li>
</ul>
</li>
<li>
<p>如何调整θ或W？</p>
<ul>
<li>$$
W_j^{t+1} = W_j^{t} - η*gradient_j
$$</li>
</ul>
</li>
<li>
<p>怎么判断收敛？</p>
<ul>
<li>判断收敛这里使用 g=0 其实并不合理，因为当损失函数是非凸函数的话 g=0 有可 能是极大值对吗！所以其实我们判断 loss 的下降收益更合理，当随着迭代 loss 减 小的幅度即收益不再变化就可以认为停止在最低点，收敛！</li>
</ul>
</li>
</ul>
<h4 id="损失函数的导函数">损失函数的导函数</h4>
<p>以多元线性回归的损失函数MSE为例
$$
\frac{\partial}{\partialθ_j}J(θ) = \frac{\partial}{\partialθ_j}\frac{1}{2}(h_θ(x)-y)^2
\= 2*\frac{1}{2}(h_θ(x)-y)<em>\frac{\partial}{\partialθ_j}(h_θ(x)-y)
\= (h_θ(x)-y)</em>\frac{\partial}{\partialθ_j}(\sum\limits_{j=0}^nθ_jx_j-y)
\= (h_θ(x)-y)x_j
$$
总结：
$$
θ_j^{t+1} = θ_j^t - η<em>g_j =  θ_j^t - η</em>(h_θ(x)-y)*x_j
$$
<br></p>
<h3 id="三种梯度下降法">三种梯度下降法</h3>
<p>区别：其实三种梯度下降的区别仅在于第 2 步求梯度所用到的 X 数据集的样本数量不同！ 它们每次学习(更新模型参数)使用的样本个数，每次更新使用不同的样本会导致每次学习的 准确性和学习时间不同。</p>
<img src="\images\gd3.png">
<h4 id="全量梯度下降">全量梯度下降</h4>
<p>$$
θ_j^{t+1} =  θ_j^t - η*\sum\limits_{i=1}^m(h_θ(x^i)-y^i)*x_j^i
$$</p>
<p>在梯度下降中，对于θ的更新，所有的样本都有贡献，也就是参与调整θ。其计算得到 的是一个标准梯度。因而理论上来说一次更新的幅度是比较大的。如果样本不多的情况下， 当然是这样收敛的速度会更快啦。全量梯度下降每次学习都使用整个训练集，因此其优点在 于每次更新都会朝着正确的方向进行，最后能够保证收敛于极值点(凸函数收敛于全局极值 点，非凸函数可能会收敛于局部极值点)，但是其缺点在于每次学习时间过长，并且如果训 练集很大以至于需要消耗大量的内存，并且全量梯度下降不能进行在线模型参数更新。</p>
<h4 id="随机梯度下降">随机梯度下降</h4>
<p>$$
θ_j^{t+1} = θ_j^t - η*(h_θ(x^i)-y^i)*x_j^i
$$</p>
<p>每次从训练集中随机选择一个样本来进行学习。批量梯度下降算法每次都 会使用全部训练样本，因此这些计算是冗余的，因为每次都使用完全相同的样本集。而随机 梯度下降算法每次只随机选择一个样本来更新模型参数，因此每次的学习是非常快速的，并 且可以进行在线更新。随机梯度下降最大的缺点在于每次更新可能并不会按照正确的方向进 行，因此可以带来优化波动(扰动)。 不过从另一个方面来看，随机梯度下降所带来的波动有个好处就是，对于类似盆地区域 （即很多局部极小值点）那么这个波动的特点可能会使得优化的方向从当前的局部极小值点 跳到另一个更好的局部极小值点，这样便可能对于非凸函数，最终收敛于一个较好的局部极 值点，甚至全局极值点。由于波动，因此会使得迭代次数（学习次数）增多，即收敛速度变 慢。不过最终其会和全量梯度下降算法一样，具有相同的收敛性，即凸函数收敛于全局极值 点，非凸损失函数收敛于局部极值点。</p>
<h4 id="小批量梯度下降">小批量梯度下降</h4>
<p>$$
θ_j^{t+1} =  θ_j^t - η*\sum\limits_{i=1}^{batch_size}(h_θ(x^i)-y^i)*x_j^i
$$</p>
<p>Mini-batch 梯度下降综合了 batch 梯度下降与 stochastic 梯度下降，在每次更新速 度与更新次数中间取得一个平衡，其每次更新从训练集中随机选择 batch_size，batch_size &lt; m 个样本进行学习。相对于随机梯度下降算法，小批量梯度下降算法降低了收敛波动性， 即降低了参数更新的方差，使得更新更加稳定。相对于全量梯度下降，其提高了每次学习的速度。并且其不用担心内存瓶颈从而可以利用矩阵运算进行高效计算。一般而言每次更新随 机选择[50,256]个样本进行学习，但是也要根据具体问题而选择，实践中可以进行多次试验， 选择一个更新速度与更次次数都较适合的样本数。</p>
<br>
<h3 id="归一化-normalization">归一化 normalization</h3>
<h4 id="归一化的目的">归一化的目的</h4>
<img src="\images\normalzaton.png">
<p>提到归一化，还是少不了梯度下降，如果维度多了，就是超平面，很难去画出来了，所 以我们选择只有两个维度的情况，那么我们可以把损失函数看作是山峰山谷，如果拿多元线 性回归举例的话，因为多元线性回归的损失函数 MSE 是凸函数，所以我们可以把损失函数 看成是一个碗。然后下面的图就是从碗上方去俯瞰！哪里是损失最小的地方呢？当然对应的 就是碗底的地方！所以下图碗中心的地方颜色较浅的区域就是 cost 损失较小的地方。 下图左是做了归一化的俯瞰图，下图右是没有做归一化的俯瞰图。</p>
<img src="\images\normalization.png">
<p>我们先来说一下为什么没做归一化是右侧图示，举个例子假如我们有一人客户信息，然 后里面有两个维度，一个是用户的年龄，一个是用户的月收入，不管目标变量是什么多元线性回归的式子我们可以里面写出来，不考虑截距项 y = θ1X1+θ2X2，那么这样每一条样本 的不同维度对应的数量级不同，原因是每个维度对应的物理含义不同嘛，但是计算机能理解 这 25 和 10000 分别是年龄和收入吗？计算机只是拿到一堆数字。</p>
<table>
<thead>
<tr>
<th>name</th>
<th>age</th>
<th>income</th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>23</td>
<td>240000</td>
</tr>
<tr>
<td>b</td>
<td>30</td>
<td>500000</td>
</tr>
<tr>
<td>c</td>
<td>40</td>
<td>800000</td>
</tr>
<tr>
<td>d</td>
<td>50</td>
<td>100000</td>
</tr>
</tbody>
</table>
<p>我们把 X1 看成是年龄，X2 看成是收入，同时我们是知道 y 的，机器学习就是知道 X,y 的情况下解方程组调整出最优解的过程。</p>
<p>根据公式我们也可以发现 y 是两部分贡献之和， 按常理来说，一开始并不知道两个部分谁更重要的情况下，可以想象为两部分对 y 的贡献是 一样的即 θ1X1 = θ2X2， 如果X1&laquo;X2,那么最终的θ1&raquo;θ2，即右图中轴θ1比轴θ2长。</p>
<p>在梯度下降第 1 步的时候所有的维度θ都是根据在期望 μ为 0 方差σ为 1 的正太分布随机在 0 附近的，就是一开始的θ1 和θ2 数值是差不多的。</p>
<p>所以可以发现θ1 从初始值到目标位置 θ1 的距离要远大于θ2 从初始值到目标位置 θ2 。</p>
<p>另外，根据前面的X1&laquo;X2,我们可以知道梯度是和X有关的，根据梯度公式
$$
g_j = (h(θ)-y)X_j
$$
可以推出g1&laquo;g2，根据梯度下降公式，可以知道对应的参数θ1每次更新的步长比θ2要小。</p>
<p>总结，根据上面得到的两个结论，我们可以发现它们互相之间是矛盾的，<strong>意味着最后θ2 需要比θ1更少的迭代次数就可以收敛，而我们要最终求得最优解，就必须每个维度θ都收敛 才可以，所以会出现θ2 等待θ1 收敛的情况。</strong></p>
<p><strong>结论：归一化的一个目的是使得最终梯度下降的时候可以不同维度θ参数可以在接近的调整幅度上， 优化的步伐是一致的。</strong></p>
<p>归一化的其它好处是有可能提高精度！一些分类器需要计算样本之间的距离（如欧氏距离）， 例如 KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）。同样的再举例分类器的例 子，由于特征维度的量纲不同，所以很可能 X1 在 10000 到 20000 的区间，X2 在 1 到 2 的区间，这样所有点都在一条直线上，出现无法找到分界线的情况。</p>
<p><strong>归一化的本质</strong>就是把 X1 和 X2 的数量级给它统一，扩展一点说，如果有更多特征维度，就要把各个特征维度 X1&hellip;Xn 的数量级统一，来做到无量纲化。</p>
<br>
<h4 id="最大最小值归一化-min-max-scaling">最大最小值归一化 min max scaling</h4>
<p>$$
X_{new} = \frac{X-X_{min}}{X_{max}-X_{min}}
$$</p>
<p>优点是一定可以把数值归一到 0 到 1 之间，缺点是如果有一个离群值，会使得一个数值为 1，其它 数值都几乎为 0，所以受离群值影响较大</p>
<br>
<h4 id="标准归一化">标准归一化</h4>
<p>通常标准归一化中包含了均值归一化和方差归一化。经过处理的数据符合标准正态分布，即均值为 0，标准差为 1。
$$
X_{new} = \frac{X-X_{mean}}{Standard\ Deviation}
$$
相对于最大值最小值归一化来说，因为标准归一化是除以的是标准差，而标准差的计算 会考虑到所有样本数据，所以受到离群值的影响会小一些，这就是除以方差的好处！但是如 果是使用标准归一化不一定会把数据缩放到 0 到1之间了。</p>
<br>
<h3 id="正则化">正则化</h3>
<h4 id="过拟合和欠拟合">过拟合和欠拟合</h4>
<p>(1) under fit：还没有拟合到位，训练集和测试集的准确率都还没有到达最高。学的还不到位。</p>
<p>(2) over fit：拟合过度，训练集的准确率升高的同时，测试集的准确率反而降低。学的过度了，做过的卷子都能再次答对，考试碰到新的没见过的题就考不好。</p>
<p>(3) just right：过拟合前训练集和测试集准确率都达到最高时刻。学习并不需要花费很多时间，理解的很好，考试的时候可以很好的把知识举一反三。真正工作中我们是奔着过拟合的状态去调的，但是最后要的模型肯定是没有过拟合的。</p>
<img src="\images\overfit.png">
<h4 id="正则化-1">正则化</h4>
<p><strong>正则化就是防止过拟合</strong>，增加模型的鲁棒性 robust，也就是让模型的泛化能力和推广能力更加的强大。</p>
<p>正则化的本质是牺牲模型在训练集上的正确率来提高推广能力，W在数值上越小越好，这样能抵抗数值的扰动。同时为了保证模型的正确率 ，W 又不能极小。 故而人们将原来的损失函数加上一个惩罚项，这里面损失函数就是原来固有的损失函数，比如回归的话通常是 MSE，分类的话通常是 cross entropy 交叉熵，然后在加上一部分惩罚 项来使得计算出来的模型 W 相对小一些来带来泛化能力。</p>
<p>常用的惩罚项有L1正则项或者L2正则项
$$
L_1 = \sum\limits_{i=0}^m|w_i|
\
L_2 = \sum\limits_{i=0}^mw_i^2
$$
其实 L1 和 L2 正则的公式数学里面的意义就是范数，代表空间中向量到原点的距离。</p>
<p>当我们把多元线性回归损失函数加上 L2 正则的时候，就诞生了 <strong>Ridge 岭回归</strong>。当我们 把多元线性回归损失函数加上 L1 正则的时候，就孕育出来了 <strong>Lasso 回归</strong>。其实 L1 和 L2 正 则项惩罚项可以加到任何算法的损失函数上面去提高计算出来模型的泛化能力的。</p>
<br>
<h3 id="多项式升维">多项式升维</h3>
<p>升维的目的是为了去解决欠拟合的问题的，也就是为了提高模型的准确率为目的的，因 为当维度不够时，说白了就是对于预测结果考虑的因素少的话，肯定不能准确的计算出模型。</p>
<p>在做升维的时候，最常见的手段就是将已知维度进行相乘来构建新的维度，多项式回归是升维的一种，它可以算是机器学习中的一种算法，不过和归一化一样一般 算作数据预处理的手段，在 sklearn 模块下它处于 sklearn.preprocessing 模块下。它的目的就是将已有维度进行相乘，包括自己和自己相乘，来组成二阶的甚至更高阶的维度。比如我们数 据集有两个维度 X1、X2 ，当我们去使 用二阶多项式升维的时候，数据集就从原来的 X1、X2 扩展成了
$$
X1,X2,X_1^2,X_2^2,X_1X_2
$$</p>





<footer class=" footline" >
	
</footer>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>