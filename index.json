[
{
	"uri": "http://example.org/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "刘顿 华中科技大学硕士研究生在读\n瞎搞算法，搞到自闭了，准备run开发~\n"
},
{
	"uri": "http://example.org/programs/bodyassessment/",
	"title": "BodyAssessment",
	"tags": [],
	"description": "",
	"content": "基于深度学习的产后妇女身体姿态检测系统 图像处理 "
},
{
	"uri": "http://example.org/resume/",
	"title": "个人简历",
	"tags": [],
	"description": "",
	"content": "  刘 顿   23 岁 男 湖北武汉   （0）137-2039-5441   zdunliu@163.com    自我评价  学习能力强，有一定的项目经验，能够自学掌握深度学习的基本知识，并运用到项目实践中。性格沉稳，能够有条不紊地安排工作流程。具有一定的思考分析问题的能力，遇到技术瓶颈可以冷静思考，理清思路，找到解决问题的方法。通过项目实践和各个程序设计比赛积累了一定的代码能力。\n 教育背景 2021 年 9 月——2024 年 6 月 华中科技大学 计算机技术  实验室：医学图像信息研究中心\n 研究方向：医学图像处理\n 主修课程：数字图像处理技术及应用，生物医学图像处理，计算机视觉， 图像处理软件开发与设计实践\n2017 年 9 月——2021 年 6 月 武汉纺织大学 软件工程(大数据方向)  主修课程：数据科学导论,大数据可视化, 机器学习, 数据采集与网络爬虫,Python 数据分析与挖掘\n 学业表现：本科期间 GPA 为 3.88，智育成绩排名平均班级前 13%\n 在校奖励：多次获得三好学生及校级奖学金，蓝桥杯省赛三等奖(C++)，\n “泰迪杯”数据挖掘挑战赛省级一等奖， 微信小程序大赛华中赛区三等奖\n 获得证书：CET4,CET6\n2014 年 9 月——2017 年 6 月 武汉市蔡甸区汉阳一中  学业表现：学渣刷题机器~\n2011 年 9 月——2014 年 6 月 蔡甸区奓山中学  (一个个人觉得更高级的说法：汉阳县第十九中学)\n 学业表现：学渣做题家~\n2004 年 9 月——2011 年 6 月 蔡甸区奓山中心小学  学业表现：平平无奇~\n 项目经历 基于深度学习的产后妇女形体评估系统（2021.08-至今）  担当角色：主要成员\n 主要工作： 该系统首先通过 kinect 深度相机采集体表的深度图像，经过预处理后分割 出人体区域。然后通过深度学习的方式识别出人体体表主要关键点的位置，同时利用深度 图 像的空间映射关系计算出肩膀，脊椎，骨盆，下肢区域的指标数值，最后以图表的方式呈现 结果。（本项目是 2020 届师兄的毕业论文，前面还有两个 2021 届师兄师姐），本人目前的主要工作是对分割出人体的深度图像进行进一步处理，以优化显示效果，例如各种滤波，目 前正在尝试使用水平集方法检测人体边缘轮廓并进行平滑。\n 主要收获： 学习掌握了 OpenCV、QT、VTK 等用于图像及 UI 界面开发的框架，积累了 C++项目经验。\n“泰迪杯”数据挖掘挑战赛（2020，春）  担当角色：组长\n 主要工作：电力巡检智能缺陷检测，实现对绝缘子串珠的分割以及对自爆绝缘子的识别和定位，即目标检测。\n 主要收获：了解了图像分割，分类，目标检测的主要任务和区别，学习了用于目标检测 的 yolo 神经网络。\n2020 微信小程序应用开发赛（2020，春）  担当角色：核心成员\n 主要工作：实现一个基于面部表情识别的生活类微信小程序。完成了前端页面的设计， 以及神经网络的构建及部署。\n 主要收获：掌握了如何将一个神经网络部署到具体的应用，锻炼了前端的代码能力。对 一个软件的开发流程有所掌握，即从需求分析到最终的成品的过程。 熟悉了 JavaScript， Html，CSS。\n基于鼠脑数据集的细胞和血管分割（2019.09-2021.03）  担当角色：核心成员\n 主要工作：对鼠脑 MOST 图像采用深度学习及图像处理方法进行分割，得到目标区域 (胞体和血管)。实现了同时对细胞体和血管进多标签的图像分割，准确率均达到 98%以上。 基于此项目，有一篇 SCI 论文已发表。\n 主要收获：对进行一个完整的数据分析的流程有所掌握，从数据预处理到搭建神经网络以及数据后处理。积累了关于图像处理，计算机视觉，深度学习神经网络的相关知识。对 keras(TF),docker,opencv 等相关技术有所了解。\n鼠脑神经元人工重建(2018，夏)  担当角色：组长/志愿者\n 主要工作：协助武汉国家光电研究中心生物医学光子学功能实验室进行鼠脑神经元人工 重建的工作，在 MOST 图像上对神经元进行标注。个人完成 4 至 6 条完整神经元的标注， 作为小组长帮助队友进行实验，作为项目志愿者，帮老师检查其它小组的神经元标注，并进行纠错。\n 主要收获：了解了数据标注对于数据科学的重要性，作为小组长锻炼了团队协作能力， 作为项目志愿者锻炼了人际沟通能力\n"
},
{
	"uri": "http://example.org/piano/cannon/",
	"title": "卡农",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/piano/basic/",
	"title": "基本乐理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/piano/runrise/",
	"title": "太阳照常升起",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/piano/littlestar/",
	"title": "小星星变奏曲",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/photograph/",
	"title": "摄影",
	"tags": [],
	"description": "",
	"content": "摄影 "
},
{
	"uri": "http://example.org/machinelearning/",
	"title": "机器学习",
	"tags": [],
	"description": "",
	"content": "机器学习 "
},
{
	"uri": "http://example.org/deeplearning/",
	"title": "深度学习",
	"tags": [],
	"description": "",
	"content": "深度学习 "
},
{
	"uri": "http://example.org/algorithm/",
	"title": "算法",
	"tags": [],
	"description": "",
	"content": "算法 "
},
{
	"uri": "http://example.org/vehicle/",
	"title": "车车",
	"tags": [],
	"description": "",
	"content": "车车 "
},
{
	"uri": "http://example.org/piano/",
	"title": "钢琴",
	"tags": [],
	"description": "",
	"content": "钢琴 基本乐理 小星星变奏曲 卡农 summer 太阳照常升起 "
},
{
	"uri": "http://example.org/programs/",
	"title": "项目",
	"tags": [],
	"description": "",
	"content": "项目 "
},
{
	"uri": "http://example.org/cxx/clang/",
	"title": "C language",
	"tags": [],
	"description": "",
	"content": "常量与变量 变量 常量 常见关键字 注释 数据类型 数据类型的本质与作用 基本类型 构造类型 空类型void 指针类型 数据存储 整型存储 浮点型存储 大小端 分支、循环语句 分支语句 循环语句 操作符 算术操作符 移位操作符 位操作符 赋值操作符 单目操作符 关系操作符 逻辑操作符 条件操作符 逗号表达式 下标引用、函数调用和结构体成员 表达式求值 函数 数组 \n指针 \n动态内存管理 \n文件操作 \n代码编译 "
},
{
	"uri": "http://example.org/cxx/",
	"title": "CPP",
	"tags": [],
	"description": "",
	"content": "C++ "
},
{
	"uri": "http://example.org/cxx/cpp/",
	"title": "CPP",
	"tags": [],
	"description": "",
	"content": "C++基础 C语言 函数  函数的默认参数 在函数声明或定义的形参列表中，为形参提供默认值 函数重载  同一个作用域内，函数的形参不同，函数名相同，则这些函数构成重载函数(与返回值类型无关) 函数如何构成重载：编译器在编译时对函数进行了重命名   内联函数  定义在类内的函数会自动成为内联函数 内联函数只是对编译器的一种建议，编译器可以选择忽略这种建议 内联函数相比普通函数没有函数压栈的开销，提升了程序运行效率 内联是一种以空间换取时间的做法，省去了调用函数的开销，代码很长的函数不适合作为内联函数    引用  引用变量是所引用变量的别名，地址与原变量的地址相同 引用与指针  引用必须在定义时就要初始化 引用变量和指针变量的自增自减运算 引用和指针变量的大小   引用作为函数参数：参数传递时不会产生临时变量  类和对象 类的默认成员函数  构造函数  调用场景：类的对象在被创建时自动调用构造函数 构造函数一般完成构造对象以及初始化工作 如果没有显式定义，编译器会自动产生一个缺省的默认构造函数 无参的构造函数和全缺省值的构造函数都被认为是缺省构造函数，一个类中，缺省的构造函数只能有一个 构造函数没有返回值，可以重载，函数名与类名相同 构造函数的参数列表：  更高效(两次构造函数变成一次拷贝构造函数) const、引用、没有默认参数的构造函数的类对象必须在构造函数的初始化列表中进行初始化     析构函数  调用场景：类对象的生命周期结束会自动调用析构函数 析构函数主要完成的是内存的释放以及对象的销毁等工作 析构函数的函数名是在类名前面加上~ 如果没有显式的提供析构函数，编译器会自动生成一个默认的析构函数   拷贝构造函数  调用场景：用一个已经存在的对象创建一个新对象 拷贝构造函数其实是构造函数的重载 拷贝构造函数的参数必须是引用传参，其他传参方式会引起无穷递归 如果没有显式提供拷贝构造函数，编译器会自动生成一个默认的拷贝构造函数，在默认的拷贝构造函数中采用了浅拷贝的方式   赋值运算符重载 取地址运算符重载 const修饰的取地址运算符重载  this指针  指向类的对象的地址 构造函数和静态成员函数中不存在this指针 this隐式地存在在类的成员函数中，但可以进行显式访问  静态成员  静态成员属于类，不属于对象 静态成员变量和函数需要在类外进行定义和初始化  友元  友元类  一个类被friend class在另一个类中，这另一个类可以访问这个类的对象的成员   友元函数  友元函数可以访问类的成员    const成员函数  this指针指向的内容不能被修改  模板 函数模板  template\u0026lt;模板参数\u0026gt; 实例化函数模板 通过函数实参推演模板实参，并绑定到模板参数上  非类型模板参数 类模板  使用了类模板后，用类模板创建一个对象时必须显式地提供类型 当类中的成员函数在类外定义时，必须加上template后接模板参数列表 返回值，类名作为形参 需要加上模板参数列表  分离编译  类的定义和类中函数的定义放在一个文件中  模板的特化  重新定义模板时在模板参数列表中显式地指定类型  异常 异常对象  编译器使用throw抛出去的表达式  异常产生 throw 异常处理 try与catch  一个异常如果没有被捕获，则会提前终止程序 栈展开的过程中对象被自动销毁(例如在构造函数中抛出异常) 如果析构函数中要抛出异常 try语句和catch语句应写在析构函数内部  编程技巧 浅拷贝/深拷贝/写时拷贝 类型萃取 泛型编程 继承和多态 继承  继承是面向对象的重要复用手段 三种继承关系  公有继承：public  基类的非私有成员在子类访问属性不变 is-a原则   私有继承：private  基类的非私有成员都变为子类的私有成员   保护继承：protected  基类的非私有成员都变为子类的protected成员     注：基类的私有成员在派生类中不能访问 赋值兼容规则  可以用一个子类对象给一个父类对象赋值 父类对象的指针或引用可以指向子类对象 上面两条反转过来不能实现，虽然可以进行强制类型转换，但这样非常容易出现访问错误的情况   派生类的6个默认构造函数 菱形继承  在孙子类的对象中存在两份父类的成员(二义性、数据冗余) 解决方法：虚拟继承 虚拟继承  专门用来解决菱形继承中存在的二义性和数据冗余的问题 使用虚拟继承会带来性能上的损耗 采用的偏移量的方式来解决二义性的问题     纯虚函数  在函数形参列表后写上“=0”叫做纯虚函数 包含纯虚函数的类叫做抽象类，抽象类不能实例化，只有在派生类中重新定义后才能实例化出对象   把析构函数写成虚函数 不会造成内存泄漏(编译器在这一块做了特殊处理)  多态  什么是多态  一个接口，多种方法   多态的实现条件  继承关系 只有在父类定义了虚函数，并且子类重写虚函数的情况下多态才能被实现 必须是父类的指针/引用指向子类或者父类的对象   多态的实现原因\u0026mdash;虚函数列表  虚函数列表是用一块连续的内存来存储虚函数的地址 虚函数表怎么解决虚函数的重写问题  父类中的虚函数如果在子类中被重新定义，则构成重写，虚函数表中的父类函数的弟子被子类函数所覆盖 子类重写父类的虚函数形参和函数名以及返回类型必须相同 上述规则对一条无效：斜变(函数返回值类型为类本身的指针或引用时函数重写仍然发生)：父类与子类必须对应 final关键字 定义在函数的形参列表后面，不允许派生类的子类的虚构函数进行重写 override关键字 会匹配子类与父类函数名相同的函数形参和类型是否一致，不一致则会报错   单继承 只会出现一张虚函数表，虚函数表先存放父类的虚函数，再存放子类的虚函数 多继承 会出现多个虚函数表，子类的虚函数会放在第一个虚函数表中   静态多态 函数重载 静态多态主要再编译期间发生，例如函数重载在编译期间对函数名进行了重命名  动态内存管理 new和delete  new开辟空间可以进行初始化 eg: new int(10)  new[]和delete[]  new int[10]()也可以进行初始化，但只能是上面这种形式，开辟的数组被初始化为0  相比于C语言的动态内存管理，C++的动态内存管理  new new[] delete delete[]是操作符，不是函数 new和new[]在开辟空间后还调用了类的构造函数 delete和delete[]先调用析构函数，再释放内存空间 new和new[]不需要进行强制类型转换  定位new表达式  定位new表达式是在已分配的内存空间中调用构造函数初始化一个对象 new(pA)type(init-list):其中pA是指向初始化这个类并且开辟了内存空间的指针  "
},
{
	"uri": "http://example.org/bigdata/hadoop/",
	"title": "Hadoop",
	"tags": [],
	"description": "",
	"content": "Hadoop系统简介  Hadoop 是一种分析和处理大数据的软件平台，是一个用 Java 语言实现的 Apache 的开源软件框架，在大量计算机组成的集群中实现了对海量数据的分布式计算。\n Hadoop 采用 MapReduce 分布式计算框架，根据 GFS 原理开发了 HDFS（分布式文件系统），并根据 BigTable 原理开发了 HBase 数据存储系统。\n Hadoop 和 Google 内部使用的分布式计算系统原理相同，其开源特性使其成为分布式计算系统的事实上的国际标准。\n Yahoo、Facebook、Amazon，以及国内的百度、阿里巴巴等众多互联网公司都以 Hadoop 为基础搭建了自己的分布式计算系统。\n Hadoop 是一个基础框架，允许用简单的编程模型在计算机集群上对大型数据集进行分布式处理。它的设计规模从单一服务器到数千台机器，每个服务器都能提供本地计算和存储功能，框架本身提供的是计算机集群高可用的服务，不依靠硬件来提供高可用性。用户可以在不了解分布式底层细节的情况下，轻松地在 Hadoop 上开发和运行处理海量数据的应用程序。低成本、高可靠、高扩展、高有效、高容错等特性让 hadoop 成为最流行的大数据分析系统。\nHadoop 生态圈 其中，HDFS是一个提供高可用的获取应用数据的分布式文件系统；MapReduce是一个并行处理大数据集的编程模型。\nHDFS 两类节点：\n NameNode，名称节点 Master DataNode，数据节点 Worker  HDFS 总的设计思想是分而治之，即将大文件和大批量文件分布式存放在大量独立的服务器上，以便采取分而治之的方式对海量数据进行运算分析。\nHDFS 是一个主/从体系结构，从最终用户的角度来看，它就像传统的文件系统一样，可以通过目录路径对文件执行 CRUD（Create、Read、Update 和 Delete）操作。但由于分布式存储的性质，HDFS 集群拥有一个 NameNode 和一些 DataNode。NameNode 管理文件系统的元数据，DataNode 存储实际的数据。\n客户端通过联系 NameNode 来获取文件的元数据，而真正的文件 I/O 操作是直接和 DataNode 交互进行的。\nHDFS 主要针对“一次写入，多次读取”的应用场景，不适合实时交互性很强的应用场景，也不适合存储大量小文件。\nHDFS的基本思想\nHDFS 是个抽象层，底层依赖很多独立的服务器，对外提供统一的文件管理功能。基本架构如图所示\n例如，用户访问 HDFS 中的 /a/b/c.mpg 这个文件时，HDFS 负责从底层的相应服务器中读取该文件，然后返回给用户，这样用户就只需和 HDFS 打交道，而不用关心这个文件是如何存储的。\n为了解决存储结点负载不均衡的问题，HDFS 首先把一个文件分割成多个块，然后再把这些文件块存储在不同服务器上。这种方式的优势就是不怕文件太大，并且读文件的压力不会全部集中在一台服务器上，从而可以避免某个热点文件会带来的单机负载过高的问题。\n文件分块存储：\n为了保证文件的可靠性，避免一台机器坏了导致丢失文件的情况，HDFS会把每个文件块进行多个备份，一般情况下是备份3份，如图所示：\n采用分块多副本存储方式后，HDFS 文件的可靠性就大大增强了，即使某个服务器出现故障，也仍然可以完整读取文件，该方式同时还带来一个很大的好处，就是增加了文件的并发访问能力。例如，多个用户读取这个文件时，都要读取块 1，HDFS 可以根据服务器的繁忙程度，选择从哪台服务器读取块 1。\n为了管理文件，HDFS 需要记录维护一些元数据，也就是关于文件数据信息的数据，如 HDFS 中存了哪些文件，文件被分成了哪些块，每个块被放在哪台服务器上等。\nHDFS 把这些元数据抽象为一个目录树，来记录这些复杂的对应关系。这些元数据由一个单独的模块进行管理，这个模块叫作名称结点（NameNode）。存放文件块的真实服务器叫作数据结点（DataNode）。\nHDFS整体架构\nHDFS 是一个主从 Master/Slave 架构。一个 HDFS 集群包含一个 NameNode，这是一个 Master Server，用来管理文件系统的命名空间，以及调节客户端对文件的访问。一个 HDFS 集群还包括多个 DataNode，用来存储数据。\nHDFS 会对外暴露一个文件系统命名空间，并允许用户数据以文件的形式进行存储。在内部，一个文件被分成多个块并且这些块被存储在一组 DataNode 上。\n1）NameNode\n文件的元数据采用集中式存储方案存放在 NameNode 当中。NameNode 负责执行文件系统命名空间的操作，如打幵、关闭、重命名文件和目录。NameNode 同时也负责将数据块映射到对应的 DataNode 中。\n2） DataNode\nDataNode 是文件系统的工作结点。它们根据需要存储并检索数据块，并且定期向 NameNode 发送他们所存储的块的列表。文件数据块本身存储在不同的 DataNode 当中，DataNode 可以分布在不同机架上。\nDataNode 负责服务文件系统客户端发出的读/写请求。DataNode 同时也负责接收 NameNode 的指令来进行数据块的创建、删除和复制。\n3）Client\nHDFS 的 Client 会分别访问 NameNode 和 DataNode 以获取文件的元信息及内容。HDFS 集群的 Client 将直接访问 NameNode 和 DataNode，相关数据会直接从 NameNode 或者 DataNode 传送到客户端。\nNameNode 和 DataNode 都是被设计为在普通 PC 上运行的软件程序。HDFS 是用Java语言实现的，任何支持 Java 语言的机器都可以运行 NameNode 或者 DataNode。Java 语言本身的可移植性意味着 HDFS 可以被广泛地部署在不同的机器上。\n一个典型的部署就是，集群中的一台专用机器运行 NameNode，集群中的其他机器每台运行一个 DataNode 实例。该架构并不排除在同一台机器上运行多个 DataNode 实例的可能，但在实际的部署中很少会这么做。\n单一 NameNode 的设计极大地简化了集群的系统架构，它使得所有 HDFS 元数据的仲裁和存储都由单一 NameNode 来决定，避免了数据不一致性的问题。\nHDFS数据复制\nHDFS 可以跨机架、跨机器，可靠地存储海量文件。HDFS 把每个文件存储为一系列的数据块，除了最后一个数据块以外，一个文件的所有数据块都是相同大小的。\n为了容错，一个文件的数据块会被复制。对于每个文件来说，文件块大小和复制因子都是可配置的。应用程序可以声明一个文件的副本数。复制因子可以在文件创建时声明，并且可以在以后修改。\nNameNode 控制所有的数据块的复制决策，如下图所示。它周期性地从集群中的 DataNode 中收集心跳和数据块报告。收集到心跳则意味着 DataNode 正在提供服务。收集到的数据块报告会包含相应 DataNode 上的所有数据块列表。\n通用场景下，当复制因子是 3 时，HDFS 的放置策略是将一个副本放置到本地机架的一个结点上，另一个放在本地机架的不同结点上，最后一个放在不同机架的不同结点上。机架不可用的概率要比结点不可用的概率低很多，这一策略并不影响数据可靠性和可用性。\n当一切运行正常时，DataNode 会周期性发送心跳信息给 NameNode（默认是每 3 秒钟一次）。如果 NameNode 在预定的时间内没有收到心跳信息（默认是 10 分钟），就会认为 DataNode 出现了问题，这时候就会把该 DataNode 从集群中移除，并且启动一个进程去恢复数据。DataNode 脱离集群的原因有多种，如硬件故障、主板故障、电源老化和网络故障等。\nMapReduce   Map\n对集合中的每个元素进行同一个操作。如果想把表单里每个单元格乘以二，那么把这个函数单独地应用在每个单元格上的操作就属于映射（Map)。\n  Reduce\n  ​\t遍历集合中的元素来返回一个综合的结果。如果想找出表单里所有数字的总和，那么输出表单里一列数字的总和的任务就属于化简（Reduce)。\nMapReduce基本思想\n  分而治之\n并行计算的第一个重要问题是如何划分计算任务或者计算数据以便对划分的子任务或数据块同时进行计算。但是，一些计算问题的前后数据项之间存在很强的依赖关系，无法进行划分，只能串行计算。\n对于不可拆分的计算任务或相互间有依赖关系的数据无法进行并行计算。一个大数据若可以分为具有同样计算过程的数据块，并且这些数据块之间不存在数据依赖关系，则提高处理速度的最好办法就是并行计算。\n  抽象模型：Map函数和Reduce函数\nMap 函数对一组数据元素进行某种重复式的处理，Reduce 函数对 Map 函数的中间结果进行某种进一步的结果整理。\n1) Map:\u0026lt;k1,v1\u0026gt;List(\u0026lt;K2,V2\u0026gt;)\n输入：键值对\u0026lt;k1,v1\u0026gt;表示的数据。\n处理：数据记录将以“键值对”形式传入 Map 函数；Map 函数将处理这些键值对，并以另一种键值对形式输出中间结果 List(\u0026lt;K2,V2\u0026gt;)。\n输出：键值对List(\u0026lt;K2,V2\u0026gt;)示的一组中间数据。\n2) Reduce:\u0026lt;K2,List(V2)\u0026gt;→List(\u0026lt;K3,V3\u0026gt;)\n输入：由 Map 输出的一组键值对 List(\u0026lt;K2,V2\u0026gt;)将被进行合并处理，同样主键下的不同数值会合并到一个列表List(V2)中，故 Reduce 的输入为\u0026lt;K2,List(V2)\u0026gt;。\n处理：对传入的中间结果列表数据进行某种整理或进一步的处理，并产生最终的输出结果List(\u0026lt;K3,V3\u0026gt;)。\n输出：最终输出结果List(\u0026lt;K3,V3\u0026gt;)。\n   函数 输入 输出 注解     Map Map\u0026lt;k1,V1\u0026gt; List(\u0026lt;k1,V2\u0026gt;) 将输入数据集分解成一批\u0026lt;key,value\u0026gt;对，然后进行处理；每一个\u0026lt;key,value\u0026gt;输入，Map 会输出一批\u0026lt;K2,V2\u0026gt;   Reduce \u0026lt;k2,List(V2)\u0026gt; \u0026lt;K3,V3\u0026gt; MapReduce 框架会把 Map 的输出，按 key 归类为 \u0026lt;K2,List(V2)\u0026gt;。List(V2) 是一批属于同一个 K2 的 value      并行自动化并隐藏底层细节\nMapReduce 提供了一个统一的计算框架，来完成计算任务的划分和调度，数据的分布存储和划分，处理数据与计算任务的同步，结果数据的收集整理，系统通信、负载平衡、计算性能优化、系统结点出错检测和失效恢复处理等。\nMapReduce 通过抽象模型和计算框架把需要做什么与具体怎么做分开了，为程序员提供了一个抽象和高层的编程接口和框架，程序员仅需要关心其应用层的具体计算问题，仅需编写少量的处理应用本身计算问题的程序代码。\n与具体完成并行计算任务相关的诸多系统层细节被隐藏起来，交给计算框架去处理：从分布代码的执行，到大到数千个，小到单个的结点集群的自动调度使用。\nMapReduce 计算架构提供的主要功能包括以下几点。\n1）任务调度\n提交的一个计算作业（Job)将被划分为很多个计算任务（Tasks)。\n任务调度功能主要负责为这些划分后的计算任务分配和调度计算结点（Map 结点或 Reduce 结点），同时负责监控这些结点的执行状态，以及 Map 结点执行的同步控制，也负责进行一些计算性能优化处理。例如，对最慢的计算任务采用多备份执行，选最快完成者作为结果。\n2）数据/程序互定位\n为了减少数据通信量，一个基本原则是本地化数据处理，即一个计算结点尽可能处理其本地磁盘上分布存储的数据，这实现了代码向数据的迁移。\n当无法进行这种本地化数据处理时，再寻找其他可用结点并将数据从网络上传送给该结点（数据向代码迁移)，但将尽可能从数据所在的本地机架上寻找可用结点以减少通信延迟。\n3）出错处理\n在以低端商用服务器构成的大规模 MapReduce 计算集群中，结点硬件（主机、兹盘、内存等）出错和软件有缺陷是常态。因此，MapReduce 架构需要能检测并隔离出错结点，并调度分配新的结点接管出错结点的计算任务。\n4）分布式数据存储与文件管理\n海量数据处理需要一个良好的分布数据存储和文件管理系统作为支撑，该系统能够把海量数据分布存储在各个结点的本地磁盘上，但保持整个数据在逻辑上成为一个完整的数据文件。\n为了提供数据存储容错机制，该系统还要提供数据块的多备份存储管理能力。\n5）Combiner 和 Partitioner\n为了减少数据通信开销，中间结果数据进入 Reduce 结点前需要进行合并（Combine）处理，即把具有同样主键的数据合并到一起避免重复传送。\n一个 Reduce 结点所处理的数据可能会来自多个 Map 结点，因此，Map 结点输出的中间结果需使用一定的策略进行适当的划分（Partition）处理，保证相关数据发送到同一个 Reduce 结点上。\n  MapReduce架构\nHadoop的MapReduce与HDFS集群架构：\nMapReduce工作流程\nWordCount\n 分割   Map   Map端排序及Combine过程   Reduce端排序及输出结果  MapReduce作业执行流程\n 提交作业  客户端向 JobTracker 提交作业。首先，用户需要将所有应该配置的参数根据需求配置好。作业提交之后，就会进入自动化执行。在这个过程中，用户只能监控程序的执行情况和强制中断作业，但是不能对作业的执行过程进行任何干预。提交作业的基本过程如下。\n**1）**客户端通过 Runjob() 方法启动作业提交过程。\n**2）**客户端通过 JobTracker 的 getNewJobId() 请求一个新的作业 ID。\n**3）**客户端检查作业的输出说明，计算作业的输入分片等，如果有问题，就抛出异常，如果正常，就将运行作业所需的资源（如作业 Jar 文件，配置文件，计算所得的输入分片等）复制到一个以作业 ID 命名的目录中。\n**4）**通过调用 JobTracker 的 submitjob() 方法告知作业准备执行。\n初始化作业  JobTracker 在 JobTracker 端开始初始化工作，包括在其内存里建立一系列数据结构，来记录这个 Job 的运行情况。\n**1）**JobTracker 接收到对其 submitJob() 方法的调用后，就会把这个调用放入一个内部队列中，交由作业调度器进行调度。初始化主要是创建一个表示正在运行作业的对象，以便跟踪任务的状态和进程。\n**2）**为了创建任务运行列表，作业调度器首先从 HDFS 中获取 JobClient 已计算好的输入分片信息，然后为每个分片创建一个 MapTask，并且创建 ReduceTask。\n分配任务  JobTracker 会向 HDFS 的 NameNode 询问有关数据在哪些文件里面，这些文件分别散落在哪些结点里面。JobTracker 需要按照“就近运行”原则分配任务。\nTaskTracker 定期通过“心跳”与 JobTracker 进行通信，主要是告知 JobTracker 自身是否还存活，以及是否已经准备好运行新的任务等。\nJobTracker 接收到心跳信息后，如果有待分配的任务，就会为 TaskTracker 分配一个任务，并将分配信息封装在心跳通信的返回值中返回给 TaskTracker。\n对于 Map 任务，JobTracker 通常会选取一个距离其输入分片最近的 TaskTracker，对于 Reduce 任务，JobTracker 则无法考虑数据的本地化。\n执行任务  **1）**TaskTracker 分配到一个任务后，通过 HDFS 把作业的 Jar 文件复制到 TaskTracker 所在的文件系统，同时，TaskTracker 将应用程序所需要的全部文件从分布式缓存复制到本地磁盘。TaskTracker 为任务新建一个本地工作目录，并把 Jar 文件中的内容解压到这个文件夹中。\n**2）**TaskTracker 启动一个新的 JVM 来运行每个任务（包括 Map 任务和 Reduce 任务），这样，JobClient 的 MapReduce 就不会影响 TaskTracker 守护进程。任务的子进程每隔几秒便告知父进程它的进度，直到任务完成。\n进程和状态的更新  一个作业和它的每个任务都有一个状态信息，包括作业或任务的运行状态，Map 任务和 Reduce 任务的进度，计数器值，状态消息或描述。任务在运行时，对其进度保持追踪。\n这些消息通过一定的时间间隔由 ChildJVM 向 TaskTracker 汇聚，然后再向 JobTracker 汇聚。JobTracker 将产生一个表明所有运行作业及其任务状态的全局视图，用户可以通过 Web UI 进行查看。JobClient 通过每秒查询 JobTracker 来获得最新状态，并且输出到控制台上。\n作业的完成  当 JobTracker 接收到的这次作业的最后一个任务已经完成时，它会将 Job 的状态改为“successful”。当 JobClient 获取到作业的状态时，就知道该作业已经成功完成，然后 JobClient 打印信息告知用户作业已成功结束，最后从 Runjob() 方法返回。\nShuffle过程\nHadoop MapReduce 的 Shuffle 阶段是指从 Map 的输出开始，包括系统执行排序，以及传送 Map 输出到 Reduce 作为输入的过程。\n排序阶段是指对 Map 端输出的 Key 进行排序的过程。不同的 Map 可能输出相同的 Key，相同的 Key 必须发送到同一个 Reduce 端处理。Shuffle 阶段可以分为 Map 端的 Shuffle 阶段和 Reduce 端的 Shuffle 阶段。\n Map 端的 Shuffle 阶段  1）每个输入分片会让一个 Map 任务来处理，默认情况下，以 HDFS 的一个块的大小（默认为 64MB）为一个分片。Map 函数开始产生输出时，并不是简单地把数据写到磁盘中，因为频繁的磁盘操作会导致性能严重下降。它的处理过程是把数据首先写到内存中的一个缓冲区， 并做一些预排序，以提升效率。\n**2）**每个 Map 任务都有一个用来写入输出数据的循环内存缓冲区（默认大小为 100MB)，当缓冲区中的数据量达到一个特定阈值（默认是 80%）时，系统将会启动一个后台线程，把缓冲区中的内容写到磁盘中（即 Spilt阶段)。在写磁盘过程中，Map 输出继续被写到缓冲区中，但如果在此期间缓冲区被填满，那么 Map 任务就会阻塞直到写磁盘过程完成。\n3）在写磁盘前，线程首先根据数据最终要传递到的 Reduce 任务把数据划分成相应的分区（Partition）。在每个分区中，后台线程按 Key 进行排序，如果有一个 Combiner，便会在排序后的输出上运行。\n**4）**一旦内存缓冲区达到溢出写的阈值，就会创建一个溢出写文件，因此在 Map 任务完成其最后一个输出记录后，便会有多个溢出写文件。在 Map 任务完成前，溢出写文件被合并成一个索引文件和数据文件（多路归并排序）（Sort 阶段)。\n**5）**溢出写文件归并完毕后，Map 任务将删除所有的临时溢出写文件，并告知 TaskTracker 任务已完成，只要其中一个 Map 任务完成，Reduce 任务就会开始复制它的输出（Copy 阶段)。\n**6）**Map 任务的输出文件放置在运行 Map 任务的 TaskTracker 的本地磁盘上，它是运行 Reduce 任务的 TaskTracker 所需要的输入数据。\nReduce 端的 Shuffle 阶段  **1）**Reduce 进程启动一些数据复制线程，请求 Map 任务所在的 TaskTracker 以获取输出文件（Copy 阶段）。\n**2）**将 Map 端复制过来的数据先放入内存缓冲区中，Merge 有 3 种形式，分别是内存到内存，内存到磁盘，磁盘到磁盘。默认情况下，第一种形式不启用，第二种形式一直在运行（Spilt阶段），直到结束，第三种形式生成最终的文件（Merge 阶段）。\n**3）**最终文件可能存在于磁盘中，也可能存在于内存中，但是默认情况下是位于磁盘中的。当 Reduce 的输入文件已定，整个 Shuffle 阶段就结束了，然后就是 Reduce 执行，把结果放到 HDFS 中（Reduce 阶段）。\n"
},
{
	"uri": "http://example.org/programs/joyyourmind/",
	"title": "JoyYourMind",
	"tags": [],
	"description": "",
	"content": "“悦君”小程序 本程序理念见简历“微信小程序”\n感谢 武汉纺织大学2021届黄佳，范美琳同学\n开个坑在这放着，让自己有个做的动力~~\n"
},
{
	"uri": "http://example.org/programs/millenniumtemple/",
	"title": "MillenniumTemple",
	"tags": [],
	"description": "",
	"content": "“千禧寺”小程序 设计作者：彭雨薇 江汉大学\nhttps://www.canva.cn/design/DAEae4EubYs/faN11NrdqF_U7tQiF_aijQ/edit#1\n开个坑在这放着，让自己有个做的动力~~\n系统架构 "
},
{
	"uri": "http://example.org/bigdata/spark/",
	"title": "Spark",
	"tags": [],
	"description": "",
	"content": "Spark环境搭建(Linux)  在Linux上搭建spark环境，使用VMWare,安装Ubuntu22.04系统\n1、安装JDK 参考文献：https://blog.csdn.net/ZhangYing_Jie/article/details/124314495\nsudo表示切换用户权限，也可以先 su root切换到root用户\n在/usr/local/中创建java目录\nsudo mkdir /usr/local/java Java官网下载jdk8\n解压JDK到java目录\nsudo tar -zxvf jdk-18_linux-x64_bin.tar.gz -C /usr/local/java/ 配置环境变量\nvi /etc/profile 按下字母i进入insert模式\n也可以使用gedit编辑\ngedit /etc/profile 打开文件后在末尾加入\nJAVA_HOME=/usr/local/java/jdk PATH=$JAVA_HOME/bin:$PATH CLASSPATH=$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jar export PATH JAVA_HOME CLASSPATH 使得修改生效：\nsource /etc/profile 也可以直接使用如下命令安装JDK\nsudo apt install openjdk-8-jre-headless 检查是否安装成功：\njava -version 2、安装Scala  安装scala  ​\t按照提示安装即可，但是官网下载会很慢，还有可能被墙\n​\t使用镜像站(https://distfiles.macports.org/scala3.1/)，下载压缩包解压,配置环境变量\n​\t或者直接使用命令\nsudo apt install scala ​\t检查是否安装成功\n3、安装Spark 下载压缩包（https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz）\n解压到/opt/spark-hadoop\n配置环境变量\n# java\nJAVA_HOME=/usr/local/java/jdk PATH=$JAVA_HOME/bin:$PATH CLASSPATH=$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jar export PATH JAVA_HOME CLASSPATH\n#scala\nexport SCALA_HOME=/opt/scala3-3.1.2 export PATH=${SCALA_HOME}/bin:$PATH\n#spark\nexport SPARK_HOME=/opt/spark-hadoop/\nexport PYTHONPATH=/opt/spark-hadoop/python\n启动spark\n4、测试Spark可用 将py4j目录移动到python目录下\n启动python,调用pyspark\nSpark简介 根据 Hadoop MapReduce 的工作流程，可以分析出 Hadoop MapRedcue 的一些缺点。\n1）Hadoop MapRedue 的表达能力有限。\n所有计算都需要转换成 Map 和 Reduce 两个操作，不能适用于所有场景，对于复杂的数据处理过程难以描述。\n2）磁盘 I/O 开销大。\nHadoop MapReduce 要求每个步骤间的数据序列化到磁盘，所以 I/O 成本很高，导致交互分析和迭代算法开销很大，而几乎所有的最优化和机器学习都是迭代的。所以，Hadoop MapReduce 不适合于交互分析和机器学习。\n3）计算延迟高。\n如果想要完成比较复杂的工作，就必须将一系列的 MapReduce 作业串联起来然后顺序执行这些作业。每一个作业都是高时延的，而且只有在前一个作业完成之后下一个作业才能开始启动。因此，Hadoop MapReduce 不能胜任比较复杂的、多阶段的计算服务。\nSpark 是借鉴了 Hadoop MapReduce 技术发展而来的，继承了其分布式并行计算的优点并改进了 MapReduce 明显的缺陷。\nSpark 使用 Scala 语言进行实现，它是一种面向对象的函数式编程语言，能够像操作本地集合对象一样轻松地操作分布式数据集。它具有运行速度快、易用性好、通用性强和随处运行等特点，具体优势如下。\n1）Spark 提供了内存计算，把中间结果放到内存中，带来了更高的迭代运算效率。通过支持有向无环图（DAG）的分布式并行计算的编程框架，Spark 减少了迭代过程中数据需要写入磁盘的需求，提高了处理效率。\n**2）**Spark 为我们提供了一个全面、统一的框架，用于管理各种有着不同性质（文本数据、图表数据等）的数据集和数据源（批量数据或实时的流数据）的大数据处理的需求。\nSpark 使用函数式编程范式扩展了 MapReduce 模型以支持更多计算类型，可以涵盖广泛的工作流，这些工作流之前被实现为 Hadoop 之上的特殊系统。\nSpark 使用内存缓存来提升性能，因此进行交互式分析也足够快速，缓存同时提升了迭代算法的性能，这使得 Spark 非常适合数据理论任务，特别是机器学习。\n**3）Spark 比 Hadoop 更加通用。**Hadoop 只提供了 Map 和 Reduce 两种处理操作，而 Spark 提供的数据集操作类型更加丰富，从而可以支持更多类型的应用。\nSpark 的计算模式也属于 MapReduce 类型，但提供的操作不仅包括 Map 和 Reduce，还提供了包括 Map、Filter、FlatMap、Sample、GroupByKey、ReduceByKey、Union、Join、Cogroup、MapValues、Sort、PartionBy 等多种转换操作，以及 Count、Collect、Reduce、Lookup、Save 等行为操作。\n4）Spark 基于 DAG 的任务调度执行机制比 Hadoop MapReduce 的迭代执行机制更优越。\nSpark 各个处理结点之间的通信模型不再像 Hadoop 一样只有 Shuffle 一种模式，程序开发者可以使用 DAG 开发复杂的多步数据管道，控制中间结果的存储、分区等。\nRDD Spark 的核心是建立在统一的抽象弹性分布式数据集（Resiliennt Distributed Datasets，RDD）之上的\nRDD基本概念 通俗点来讲，可以将 RDD 理解为一个分布式对象集合，本质上是一个只读的分区记录集合。每个 RDD 可以分成多个分区，每个分区就是一个数据集片段。一个 RDD 的不同分区可以保存到集群中的不同结点上，从而可以在集群中的不同结点上进行并行计算。\nRDD 的分区及分区与工作结点（Worker Node）的分布关系：\nRDD 具有容错机制，并且只读不能修改，可以执行确定的转换操作创建新的 RDD。具体来讲，RDD 具有以下几个属性。\n 只读：不能修改，只能通过转换操作生成新的 RDD。 分布式：可以分布在多台机器上进行并行处理。 弹性：计算过程中内存不够时它会和磁盘进行数据交换。 基于内存：可以全部或部分缓存在内存中，在多次计算间重用。  RDD基本操作 RDD 的操作分为转化（Transformation）操作和行动（Action）操作。转化操作就是从一个 RDD 产生一个新的 RDD，而行动操作就是进行实际的计算。\nRDD 的操作是惰性的，当 RDD 执行转化操作的时候，实际计算并没有被执行，只有当 RDD 执行行动操作时才会促发计算任务提交，从而执行相应的计算操作。\n1、构建RDD\n  从内存里直接读取数据\nval rdd01 = sc.makeRDD(List(l,2,3,4,5,6))   从文件系统里读取数据（HDFS、本地文件系统等）\nval rdd:RDD[String] == sc.textFile(\u0026#34;file:///D:/sparkdata.txt\u0026#34;,1)   2、转换操作transformation\nRDD转换操作（rdd1={1, 2, 3, 3}，rdd2={3,4,5})\n   函数名 作用 示例 结果     map() 将函数应用于 RDD 的每个元素，返回值是新的 RDD rdd1.map(x=\u0026gt;x+l) {2,3,4,4}   flatMap() 将函数应用于 RDD 的每个元素，将元素数据进行拆分，变成迭代器，返回值是新的 RDD rdd1.flatMap(x=\u0026gt;x.to(3)) {1,2,3,2,3,3,3}   filter() 函数会过滤掉不符合条件的元素，返回值是新的 RDD rdd1.filter(x=\u0026gt;x!=1) {2,3,3}   distinct() 将 RDD 里的元素进行去重操作 rdd1.distinct() (1,2,3)   union() 生成包含两个 RDD 所有元素的新的 RDD rdd1.union(rdd2) {1,2,3,3,3,4,5}   intersection() 求出两个 RDD 的共同元素 rdd1.intersection(rdd2) {3}   subtract() 将原 RDD 里和参数 RDD 里相同的元素去掉 rdd1.subtract(rdd2) {1,2}   cartesian() 求两个 RDD 的笛卡儿积 rdd1.cartesian(rdd2) {(1,3),(1,4)\u0026hellip;\u0026hellip;(3,5)}    3、行动操作action\nRDD 行动操作（rdd={1,2,3,3}）\n   函数名 作用 示例 结果     collect() 返回 RDD 的所有元素 rdd.collect() {1,2,3,3}   count() RDD 里元素的个数 rdd.count() 4   countByValue() 各元素在 RDD 中的出现次数 rdd.countByValue() {(1,1),(2,1),(3,2})}   take(num) 从 RDD 中返回 num 个元素 rdd.take(2) {1,2}   top(num) 从 RDD 中，按照默认（降序）或者指定的排序返回最前面的 num 个元素 rdd.top(2) {3,3}   reduce() 并行整合所有 RDD 数据，如求和操作 rdd.reduce((x,y)=\u0026gt;x+y) 9   fold(zero)(func) 和 reduce() 功能一样，但需要提供初始值 rdd.fold(0)((x,y)=\u0026gt;x+y) 9   foreach(func) 对 RDD 的每个元素都使用特定函数 rdd1.foreach(x=\u0026gt;printIn(x)) 打印每一个元素   saveAsTextFile(path) 将数据集的元素，以文本的形式保存到文件系统中 rdd1.saveAsTextFile(file://home/test)    saveAsSequenceFile(path) 将数据集的元素，以顺序文件格式保存到指 定的目录下 saveAsSequenceFile(hdfs://home/test)     RDD血缘关系 RDD 的最重要的特性之一就是血缘关系（Lineage )，它描述了一个 RDD 是如何从父 RDD 计算得来的。如果某个 RDD 丢失了，则可以根据血缘关系，从父 RDD 计算得来。\n下图给出了一个 RDD 执行过程的实例。系统从输入中逻辑上生成了 A 和 C 两个 RDD， 经过一系列转换操作，逻辑上生成了 F 这个 RDD。\nSpark 记录了 RDD 之间的生成和依赖关系。当 F 进行行动操作时，Spark 才会根据 RDD 的依赖关系生成 DAG，并从起点开始真正的计算。\nRDD依赖类型 根据不同的转换操作，RDD 血缘关系的依赖分为窄依赖和宽依赖。窄依赖是指父 RDD 的每个分区都只被子 RDD 的一个分区所使用。宽依赖是指父 RDD 的每个分区都被多个子 RDD 的分区所依赖。\nRDD几大特性 五大特性：\n  A list of partitions\nRDD是由一系列partition组成(block块对应partition),textFile底层调用的是MR读取hdfs上的数据的方法\n默认一个block块对应一个split,split的大小和block大小一致,可以自己调整\n  A function for computing each split\n函数作用在每一个partition(split)上\n  A list of dependencies on other RDDs\nRDD之间有一系列的依赖关系(容错机制)\n  Optionally, a Partitioner for key-value RDDs\n分区器作用在K,V格式的RDD上\n  Optionally, a list of preferred locations to compute each split on\nRDD 提供一系列最佳的计算位置\n  Spark总体架构 Spark运行流程 Windows配置Spark https://blog.csdn.net/qq_52491380/article/details/120787037\nDocker\u0026ndash;Spark 安装docker后运行如下命令\njupyter/pyspark-notebook 是docker官方镜像\ndocker run -p 8888:8888 jupyter/pyspark-notebook 将docker容器内8888端口映射到本地的8888端口\nPySpark_Wordcount from pyspark import SparkConf, SparkContext from pyspark.storagelevel import StorageLevel  conf = SparkConf().setMaster(\u0026#34;local\u0026#34;).setAppName(\u0026#34;wordcount\u0026#34;) sc = SparkContext(conf=conf) sc.setCheckpointDir(\u0026#34;.\u0026#34;)  data1 = [\u0026#39;I like Edison Chan\u0026#39;, \u0026#39;I like Eason Chan\u0026#39;, \u0026#39;I love myself\u0026#39;] rdd1 = sc.parallelize(data1) result = rdd1.flatMap(lambda x: x.split()).map(lambda word: (word, 1)).reduceByKey(lambda x, y: x+y) result.foreach(print) 输出每一步的RDD：\nrdd1 = sc.parallelize(data1) rdd1.foreach(print) # result = rdd1.flatMap(lambda x: x.split()).map(lambda word: (word, 1)).reduceByKey(lambda x, y: x+y) # result.foreach(print) rdd2 = rdd1.flatMap(lambda x: x.split()) rdd2.foreach(print) rdd3 = rdd2.map(lambda word:(word,1)) rdd3.foreach(print) rdd4 = rdd3.reduceByKey(lambda x,y: x+y) rdd4.foreach(print) 原始数据：\nflat:\nmap:\nreduce:\n"
},
{
	"uri": "http://example.org/bigdata/",
	"title": "大数据",
	"tags": [],
	"description": "",
	"content": "大数据 参考文献\nhttp://c.biancheng.net/view/3500.html\n"
},
{
	"uri": "http://example.org/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://example.org/programs/bodyassessment/imageprocess/",
	"title": "ImageProcess",
	"tags": [],
	"description": "",
	"content": "滤波 采用双边滤波平滑人体内部\n水平集 1、Localizing Region-Based Active Contours 2022-03-12 —— 2022-04-09\n  代码流程：\n  初始化轮廓为一个包含人体的矩形，内部为+c，外部为-c。（c=2）\n  开始演化\n  计算狄拉克函数\n作用是表明轮廓曲线周围的区域\n从上到下依次是：边界，远离边界的区域，和边界附近的区域\n  计算曲率\n一阶导：, || = 先对一阶导数单位化，再求二阶导数\n曲率curvature = + 即  计算前景与背景均值\n  先计算Heaviside函数，标识水平集的内部和外部（内部为1，外部为0，边界为0~1）\n  计算前景均值\n  计算背景均值\n    计算惩罚项\n将phi与一个拉普拉斯算子做卷积运算，以突出phi的边缘\n  更新phi的每个点的值\n      实验：\n  参数\nc为水平集内部点的初值\n  结果\n    ​\t​\t​\t左图为最终的轮廓，右图为最终的水平集phi可以看到都没有平滑，调整迭代次数，时间步长，λ，μ，ν，都没有明显的效果（220326周报-全局调参）。\n​\t220402—统计时间（microseconds），尝试初始轮廓换成椭圆\n   方法 患者ID 矩形水平集20轮 椭圆水平集30轮 椭圆水平集 20轮     1 409061 632310 396968   2 410979 592415 359038   3 415397 575459 360009   4 414089 596375 356047   5 399128 566481 358014   6 391003 560502 363057   7 385457 585406 363056   8 403885 561497 355049   9 389965 547533 370980   10 385965 527591 355050   11 389469 508668 358071   12 396982 501630 363055   13 395966 496705 365023   14 395943 505646 361034   15 389438 502631 351089   16 400473 497695 349039   17 391429 516645 358040   18 381009 503682 361034   19 429991 506644 354081   均值 398717.3158 541342.8947 360933.3684    考虑到初始轮廓也可能会影响水平集方法的效果，所以尝试了用椭圆作为初始轮廓\n水平集方法按照初步调参后效果比较好的参数进行时间统计\n矩形：迭代20次，演化步长m_timestep为0.01，m_lambda=0.01，m_mu=1.0. m_nu=1.0\n椭圆：迭代30次，演化步长m_timestep为0.01，m_lambda=0.01，m_mu=1.0. m_nu=1.0\n都没有明显的平滑效果。\n2、Distance Regularized Level Set Evolution and Its Application to Image Segmentation DRLSE 2022-04-09 —— 2022-05-14\n  代码流程\n  深度图转换成灰度图\nlow和high分别为深度值的最小和最大值\n  去除srcImg中灰度大于100的部分，以去除相对人体较亮的背景\n  求edge indicator g\n先对srcImg进行高斯滤波得到gbImg\n对gbImg求梯度dx,dy,得到计算g\n​\t目标边界的g值通常比其他区域要小\n  初始化轮廓为人体内部的两个矩形\n  开始演化\n    实验\n 参数 结果    3、Fast Global Minimization of the Active Contour/Snake Model GMAC 2022-05-14 —— 2022-05-28\n4、尝试结合前面的三种模型 对点云图进行处理 2022-06-01——\n思路 分辨率、边缘平滑\nKinect相机→深度图/彩色图→点云→插值提高分辨率、保持边缘平滑、滤波→映射到二维深度图/灰度图\n整理获取图像的流程 启动界面BdAssessment，在其构造函数中新建了一个camera实例，以及一个控制相机显示的QTimer定时器\n定时器发出超时信号，触发槽函数cameraDisplay()\nstart(0)：时间间隔0毫秒，一旦窗口系统事件队列中的所有事件都已经被处理完，该QTimer就会到时间了，进行cameraDisplay()\nBdAssessment::BdAssessment(QWidget *parent): QMainWindow(parent) { \tcamera = new Camera();  cameraDisplayTimer = new QTimer();  connect(cameraDisplayTimer, SIGNAL(timeout()), this, SLOT(cameraDisplay()));  cameraDisplayTimer-\u0026gt;start(0); } 启动Kinect设备\nCamera::Camera() { \topenDevice(); } 进入cameraDisplay()\n  camera→getFrame() 获取一帧图像\ngetFrame()是一个重载函数\nUINT16* getFrame(float floorH); UINT16* getFrame(float floorH, bool\u0026amp; isBody); BYTE* getFrame(float floorH, int mode); 这里用的是第一个，getFrame(setting-\u0026gt;getHeight())，floorH是相机高度\nfloat Setting::getHeight() { \treturn ui.heightValue-\u0026gt;text().toFloat(); } IDepthFrame* pDepthFrame = nullptr; IColorFrame* pColorFrame = nullptr;\tIDepthFrameReader* m_pDepthFrameReader = nullptr; IColorFrameReader* m_pColorFrameReader = nullptr; IDepthFrame 和 IColorFrame 是Kinect中的两个类，分别用来存储深度图像和彩色图像\nIDepthFrameReader和IColorFrameReader 是Kinect中的两个类，分别用来读取深度图像和彩色图像\n1）读取深度图像\nhr = m_pDepthFrameReader-\u0026gt;AcquireLatestFrame(\u0026amp;pDepthFrame); 返回值hr表示读取是否成功\nif (SUCCEEDED(hr)) {  if (frameId \u0026gt; 149)  {  frameId++;  SafeRelease(pDepthFrame);  return depthBuffers + (frameId % 150) * 424 * 512;  }  hr = pDepthFrame-\u0026gt;CopyFrameDataToArray(depthHeight * depthWidth, depthBuffers + frameId * 424 * 512); } CopyFrameDataToArray将Kinect中的帧数据转换成一维数组(depthBuffers)，\ndepthHeight * depthWidth(424*512)为一帧的像素个数\nframeId（初值为0）用来记录帧数，最多150帧（行走图共有150帧）,存满150帧就返回depthBuffers，然后一帧一帧地返回\n2）读取彩色图像\nif (SUCCEEDED(hr)) { \thr = m_pColorFrameReader-\u0026gt;AcquireLatestFrame(\u0026amp;pColorFrame); } if (SUCCEEDED(hr)) {  hr = pColorFrame-\u0026gt;CopyConvertedFrameDataToArray(1080*1920*4, reinterpret_cast\u0026lt;BYTE*\u0026gt;(i_rgb.data), ColorImageFormat::ColorImageFormat_Bgra); } SafeRelease(pDepthFrame); SafeRelease(pColorFrame); 彩色图像是bgra四通道格式的，尺寸为1080*1920，存储到 cv::Mat i_rgb; 中\n3）数据预处理\nif (SUCCEEDED(hr)) {  float h = floorH;  for (int i = 0; i \u0026lt; depthHeight; i++)  {  for (int j = 0; j \u0026lt; depthWidth; j++)  {  DepthSpacePoint depthSpacePoint;  depthSpacePoint = { static_cast\u0026lt;float\u0026gt;(j), static_cast\u0026lt;float\u0026gt;(i) };  UINT16 currDepth = depthBuffers[i * depthWidth + j + frameId * 424 * 512];  CameraSpacePoint cameraPoint = { 0.0f, 0.0f, 0.0f };  ColorSpacePoint colorPoint = { 0.0f, 0.0f };  m_pMap-\u0026gt;MapDepthPointToCameraSpace(depthSpacePoint, currDepth, \u0026amp;cameraPoint);  if (cameraPoint.Y \u0026lt; -h || j\u0026lt;99 || j\u0026gt;99+318)  depthBuffers[i * depthWidth + j + frameId * 424 * 512] = 0;  }  }  UINT16* img = depthBuffers + frameId * 424 * 512;  /***************************************************************************************************/   BYTE* label = new BYTE[depthHeight * depthWidth]();  label[seedY * depthWidth + seedX] = 1;  queue\u0026lt;int\u0026gt; points;  points.push(seedX);  points.push(seedY);  int nearby[] = { 1, 0, -1, 0, 0, 1, 0, -1 };  int nn = 0;  while (!points.empty())  {  int x = points.front();  points.pop();  int y = points.front();  points.pop();  int value = img[y * depthWidth + x];  for (int i = 0; i \u0026lt; 4; i++)  {  int xx = x + nearby[i * 2 + 0];  int yy = y + nearby[i * 2 + 1];  xx = min(max(0, xx), depthWidth - 1);  yy = min(max(0, yy), depthHeight - 1);  if (abs(img[yy * depthWidth + xx] - value) \u0026lt; d \u0026amp;\u0026amp; label[yy*depthWidth + xx] == 0)  {  label[yy * depthWidth + xx] = 1;  nn++;  points.push(xx);  points.push(yy);  }  }  }  for (int i = 0; i \u0026lt; depthHeight; i++)  for (int j = 0; j \u0026lt; depthWidth; j++)  if (label[i*depthWidth + j] == 0)  img[i * depthWidth + j] = 0;   /***************************************************************************************************/  if (record)  {  /*if (colorFlag) { cv::Mat i_rgb2; cvtColor(i_rgb, i_rgb2, CV_RGBA2RGB); i_rgbs.push_back(i_rgb2); }*/  frameId++;  }  return img;  }  return nullptr; } DepthSpacePoint，CameraDepthPoint，ColorDepthPoint是kinect中的一个结构体\ntypedef struct _DepthSpacePoint  {  float X;  float Y;  } DepthSpacePoint;  typedef struct _CameraSpacePoint  {  float X;  float Y;  float Z;  } CameraSpacePoint;  typedef struct _ColorSpacePoint  {  float X;  float Y;  } ColorSpacePoint; depthSpacePoint = { static_cast\u0026lt;float\u0026gt;(j), static_cast\u0026lt;float\u0026gt;(i) }; CameraSpacePoint cameraPoint = { 0.0f, 0.0f, 0.0f }; ColorSpacePoint colorPoint = { 0.0f, 0.0f };\tj是列索引，i是行索引，分别对应X和Y坐标，所以坐标系如下：\ncurrDepth为深度图像的深度值\n将深度坐标转换为相机坐标，Z即为深度值\nm_pMap-\u0026gt;MapDepthPointToCameraSpace(depthSpacePoint, currDepth, \u0026amp;cameraPoint); 将比人体所在区域高和低的部分的深度值置为0\nif (cameraPoint.Y \u0026lt; -h || j\u0026lt;99 || j\u0026gt;99+318)  depthBuffers[i * depthWidth + j + frameId * 424 * 512] = 0; 取当前的帧\nUINT16* img = depthBuffers + frameId * 424 * 512; 区域增长分割人体(队列、深度差阈值)\nBYTE* label = new BYTE[depthHeight * depthWidth](); label[seedY * depthWidth + seedX] = 1; queue\u0026lt;int\u0026gt; points; points.push(seedX); points.push(seedY); int nearby[] = { 1, 0, -1, 0, 0, 1, 0, -1 }; int nn = 0; while (!points.empty()) {  int x = points.front();  points.pop();  int y = points.front();  points.pop();  int value = img[y * depthWidth + x];  for (int i = 0; i \u0026lt; 4; i++)  {  int xx = x + nearby[i * 2 + 0];  int yy = y + nearby[i * 2 + 1];  xx = min(max(0, xx), depthWidth - 1);  yy = min(max(0, yy), depthHeight - 1);  if (abs(img[yy * depthWidth + xx] - value) \u0026lt; d \u0026amp;\u0026amp; label[yy*depthWidth + xx] == 0)  {  label[yy * depthWidth + xx] = 1;  nn++;  points.push(xx);  points.push(yy);  }  } } for (int i = 0; i \u0026lt; depthHeight; i++)  for (int j = 0; j \u0026lt; depthWidth; j++)  if (label[i*depthWidth + j] == 0)  img[i * depthWidth + j] = 0; 返回分割人体后的帧，record表示是否录像\nif (record) { \tframeId++; } return img;   回到cameraDisplay()\nUINT16* depthImg = camera-\u0026gt;getFrame(setting-\u0026gt;getHeight()); if (depthImg == nullptr) \treturn; UINT16 depth = depthImg[seedY*depthWidth + seedX]; DepthSpacePoint depthSpacePoint = { static_cast\u0026lt;float\u0026gt;(seedX), static_cast\u0026lt;float\u0026gt;(seedY) }; CameraSpacePoint cameraPoint = { 0.0f, 0.0f, 0.0f }; camera-\u0026gt;m_pMap-\u0026gt;MapDepthPointToCameraSpace(depthSpacePoint, depth, \u0026amp;cameraPoint);//将深度图坐标转换到相机坐标 depthImg是camera-\u0026gt;getFrame()返回的分割出人体后的深度图\nseedX = depthWidth / 2; seedY = depthHeight / 2; 是中心种子点的坐标，depth为其深度值\ncameraPoint为人体种子点对应的相机坐标（X,Y,Z）\nif (cameraPoint.Z == -std::numeric_limits\u0026lt;float\u0026gt;::infinity())  ui.label_14-\u0026gt;setText(QStringLiteral(\u0026#34;未检测出物体\u0026#34;)); else{  ui.label_14-\u0026gt;setText(QStringLiteral(\u0026#34;距离： \u0026#34;) + QString::number(cameraPoint.Z) + \u0026#34;m\u0026#34;);  tempDis = cameraPoint.Z; } 根据种子点深度值判断是否检测出人体，\ntempDis为种子点离相机的距离，单位为m，后面需要用来判断拍摄的照片是否符合要求\nif (tempDis * 100 \u0026gt;= 230 || tempDis * 100 \u0026lt;= 170) {  mess = QStringLiteral(\u0026#34;请调整您与摄像头的距离！\u0026#34;);  flag = true; } 如果帧数达到150，保存录像\nif (camera-\u0026gt;frameId == 150) {  cameraDisplayTimer-\u0026gt;stop();  cameraDisplayTimer-\u0026gt;start(0);  saveVideo(); } 将深度值转换为灰度值[0,255]\nfor (int i = 0; i \u0026lt; 424 * 512; i++)  depthBuffers[i] = depthImg[i] % 256; 将种子点附近的值置为255\nfor (int i = seedY - 5; i \u0026lt; seedY + 5; i++)  for (int j = seedX - 20; j \u0026lt; seedX + 20; j++)  depthBuffers[i * depthWidth + j] = 255; for (int i = seedY - 20; i \u0026lt; seedY + 20; i++)  for (int j = seedX - 5; j \u0026lt; seedX + 5; j++)  depthBuffers[i * depthWidth + j] = 255; 显示\nQImage depthImgQ = QImage(depthBuffers, depthWidth, depthHeight, QImage::Format_Grayscale8); QImage depthImgROI = depthImgQ.copy(depthWidth / 2 - depthHeight * 3 / 8, 0, depthHeight * 3 / 4, depthHeight); depthImgROI = depthImgROI.scaled(ui.depthFig-\u0026gt;width(), ui.depthFig-\u0026gt;height()); ui.depthFig-\u0026gt;setPixmap(QPixmap::fromImage(depthImgROI)); \n  拍照\n点击“拍”按钮，调用函数BdAssessment::capture()\ncameraDisplayTimer-\u0026gt;stop(); QDir currDir(\u0026#34;./\u0026#34;); if (!currDir.exists(\u0026#34;Data2\u0026#34;))  currDir.mkdir(\u0026#34;Data2\u0026#34;); 首先停止cameraDisplay，然后创建存储数据的目录Data2\n调用Camer::capture()\nbool isBody = false; UINT16* depthImg = camera-\u0026gt;capture(setting-\u0026gt;getHeight(), isBody); UINT16* Camera::capture(float floorH, bool\u0026amp; isBody) { \tUINT16* img; \twhile (1) \t{ \timg = getFrame(floorH, isBody); \tif (img != nullptr) \treturn img; \t} } 这里的getFrame和前面的getFrame基本一帧，只是多了下面这一段：\nIBodyFrame* pBodyFrame = nullptr; IBodyFrameSource* pBodyFrameSource = nullptr; IBodyFrameReader* m_pBodyFrameReader = nullptr;  if (SUCCEEDED(hr)) {  m_pBodyFrameReader-\u0026gt;AcquireLatestFrame(\u0026amp;pBodyFrame); } if (SUCCEEDED(hr)) {  IBody** myBodyArr = new IBody *[BODY_COUNT];  for (int i = 0; i \u0026lt; BODY_COUNT; i++)  myBodyArr[i] = nullptr;  if (pBodyFrame-\u0026gt;GetAndRefreshBodyData(BODY_COUNT, myBodyArr) == S_OK) //把身体数据输入数组  {  for (int i = 0; i \u0026lt; BODY_COUNT; i++)  {  BOOLEAN result = false;  if (myBodyArr[i]-\u0026gt;get_IsTracked(\u0026amp;result) == S_OK \u0026amp;\u0026amp; result) //先判断是否侦测到  {  isBody = true;  break;  }  }  } } IBodyFrame，IBodyFrameSource，IBodyFrameReader也是Kinect中的类，用来判断是否侦测到身体。\n最终depthImg为getFrame()返回的分割人体后的帧\nUINT16* depthImg = camera-\u0026gt;capture(setting-\u0026gt;getHeight(), isBody); /*if (!isBody) //人体检测 { QMessageBox::information(NULL, QStringLiteral(\u0026#34;提示\u0026#34;), QStringLiteral(\u0026#34;未检测到人体，请重新拍摄\u0026#34;)); cameraDisplayTimer-\u0026gt;start(0); return; }*/ isBody是引用类型，getFrame内部通过Kinect接口判断是否检测到人体后，在capture()中根据isBody是否为true给出提示。\n保存数据\nstring depthFrameName = \u0026#34;./Data2/Depth_\u0026#34; + to_string(curId) + \u0026#34;_\u0026#34; + to_string(nextSubId) + \u0026#34;.dat\u0026#34;; ofstream f2(depthFrameName, ios::binary); f2.write(reinterpret_cast\u0026lt;char*\u0026gt;(depthImg), depthHeight * depthWidth * sizeof(UINT16)); f2.close(); 文件名为”Depth_\u0026hellip;\u0026hellip;..“的数据是分割出人体后的深度图。（还没有做滤波等处理）\n进行图像处理，其中iProFront和iProBack为ImageProcess类的实例\nswitch (nextSubId) { \tcase 1: \tiProFront-\u0026gt;terminate(); \tiProFront-\u0026gt;fileId = curId; \tiProFront-\u0026gt;subId = nextSubId; \tiProFront-\u0026gt;m_pMap = camera-\u0026gt;m_pMap; \tiProFront-\u0026gt;depthHeight = depthHeight; \tiProFront-\u0026gt;depthWidth = depthWidth; \tiProFront-\u0026gt;seedX = seedX; \tiProFront-\u0026gt;seedY = seedY; \tiProFront-\u0026gt;start(); \tbreak; \tcase 2: \tiProBack-\u0026gt;terminate(); \tiProBack-\u0026gt;fileId = curId; \tiProBack-\u0026gt;subId = nextSubId; \tiProBack-\u0026gt;m_pMap = camera-\u0026gt;m_pMap; \tiProBack-\u0026gt;depthHeight = depthHeight; \tiProBack-\u0026gt;depthWidth = depthWidth; \tiProBack-\u0026gt;seedX = seedX; \tiProBack-\u0026gt;seedY = seedY; \tiProBack-\u0026gt;start(); \tbreak; }\t\n图像处理类（ImageProcess） 将深度图像转换成点云是在这里实现的\nvoid ImageProcess::run() { \tint result; \tstring depthFrameName = \u0026#34;./Data2/Depth_\u0026#34; + to_string(fileId) + \u0026#34;_\u0026#34; + to_string(subId) + \u0026#34;.dat\u0026#34;; \tstring cloudName = \u0026#34;./Data/Cloud_\u0026#34; + to_string(fileId) + \u0026#34;_\u0026#34; + to_string(subId) + \u0026#34;.dat\u0026#34;; \tstring depthPName = \u0026#34;./Data/DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_\u0026#34; + to_string(subId) + \u0026#34;.dat\u0026#34;; \tstring depthP2Name = \u0026#34;./Data/DepthPP_\u0026#34; + to_string(fileId) + \u0026#34;_\u0026#34; + to_string(subId) + \u0026#34;.dat\u0026#34;; \tQFileInfo file2(QString::fromStdString(depthFrameName)); \tif (!(file2.isFile())) \treturn; \tf2.open(depthFrameName, ios::binary); \tf3.open(cloudName, ios::binary); \tf4.open(depthPName, ios::binary); \tf5.open(depthP2Name, ios::binary); \tint frameNum; \tif (subId == 3) \tframeNum = 150; \telse \tframeNum = 1; \tfor (int i = 0; i \u0026lt; frameNum; i++) \t{ \tif (frameNum == 150) \t{ \tofstream f(\u0026#34;num.txt\u0026#34;); \tf \u0026lt;\u0026lt; i/2; \tf.close(); \t} \tloadData(); \tresult = extractBody(); \toutputFile(); \t} \tif (subId != 3) { \tofstream f(\u0026#34;num.txt\u0026#34;); \tf \u0026lt;\u0026lt; 150 / 2; \tf.close(); \t} \tf2.close(); \tf3.close(); \tf4.close(); \tf5.close(); \tdeepLearning(); \tcompressData();  } depthFrameName，前面capture存储的分割出人体的深度图\ncloudName，\ndepthPName ，\ndepthP2Name，\n根据subId判断是正面还是背面或者行走图，设置帧数frameNum，然后遍历每一帧进行处理\nfor (int i = 0; i \u0026lt; frameNum; i++) {  if (frameNum == 150)  {  ofstream f(\u0026#34;num.txt\u0026#34;);  f \u0026lt;\u0026lt; i/2;  f.close();  }  loadData();  result = extractBody();  outputFile(); } loadData()读取深度图像，存储至depthBuffer\n//读取深度图图像 void ImageProcess::loadData() { \tf2.read(reinterpret_cast\u0026lt;char*\u0026gt;(depthBuffer), depthHeight * depthWidth * sizeof(UINT16)); \tfor (int i = 0; i \u0026lt; depthHeight; i++) \tfor (int j = 0; j \u0026lt; depthWidth; j++) \tif (j \u0026gt; depthWidth / 2 + depthHeight / 4 || j \u0026lt; depthWidth / 2 - depthHeight / 4) \tdepthBuffer[i*depthWidth + j] = 0; } \nresult = extractBody();\n  extractBody：\n// ------------------------区域生长---------------------------- int d = 20; BYTE* label = new BYTE[depthHeight * depthWidth](); label[seedY * depthWidth + seedX] = 1; queue\u0026lt;int\u0026gt; points; points.push(seedX); points.push(seedY); int nearby[] = { 1, 0, -1, 0, 0, 1, 0, -1 }; int nn = 0; while (!points.empty()) {  int x = points.front();  points.pop();  int y = points.front();  points.pop();  int value = depthBuffer[y * depthWidth + x];  for (int i = 0; i \u0026lt; 4; i++)  {  int xx = x + nearby[i * 2 + 0];  int yy = y + nearby[i * 2 + 1];  xx = min(max(0, xx), depthWidth-1);  yy = min(max(0, yy), depthHeight-1);  if (abs(depthBuffer[yy * depthWidth + xx] - value) \u0026lt; d \u0026amp;\u0026amp; label[yy*depthWidth+xx]==0)  {  label[yy * depthWidth + xx] = 1;  nn++;  points.push(xx);  points.push(yy);  }  } }  // ------------------------二次遍历，将没有标记的数据深度置为0------------------------ int hist[10000] = { 0 }, low = 10000, high = 0; int up = depthHeight, down = 0, left = depthWidth, right = 0; for (int i = 0; i \u0026lt; depthHeight; i++) {  for (int j = 0; j \u0026lt; depthWidth; j++)  {  if (label[i*depthWidth+j] == 1)  {  UINT16 value = depthBuffer[i * depthWidth + j];  depthBuffer2[i * depthWidth + j] = value;  hist[value] += 1;  if (hist[value] \u0026gt; 5)  {  if (value \u0026gt; high)  high = value;  if (value \u0026lt; low)  low = value;  }  if (i \u0026lt; up)  up = i;  if (i \u0026gt; down)  down = i;  if (j \u0026lt; left)  left = j;  if (j \u0026gt; right)  right = j;  }  else  depthBuffer2[i * depthWidth + j] = 0;  } } 利用队列和深度差进行区域生长分割人体，结果存储至depthBuffer2\nup,down,left,right分别为人体(label==1)的上下左右坐标极值(即人体的第一/最后一行/列)\nhigh和low为深度值的最大最小(需要至少出现5次,出现5次以下的深度值不予考虑)\n平滑处理，可以用均值滤波、高斯滤波、双边滤波等，结果存储至depthBuffer3\n//--------------------------图像平滑处理-----------------------------(平滑只是简单的均值滤波，用双边滤波可以改进) int* depthBuffer3 = new int[depthHeight * depthWidth](); for (int i = 2; i \u0026lt; depthHeight-2; i++) {  for (int j = 2; j \u0026lt; depthWidth-2; j++)  {  if (depthBuffer2[i * depthWidth + j] == 0 || i == 0 || j == 0 || i == depthHeight-1 || j == depthWidth-1)  continue;  int nearX[] = { -2, -1, 0, 1, 2, -2, -1, 0, 1, 2, -2, -1, 0, 1, 2, -2, -1, 0, 1, 2, -2, -1, 0, 1, 2 };  int nearY[] = { -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2 };  int k = 0;  for (k = 0; k \u0026lt; 25; k++)  {  if (depthBuffer2[(i + nearX[k]) * depthWidth + j + nearY[k]] == 0)  break;  depthBuffer3[i * depthWidth + j] += depthBuffer2[(i + nearX[k]) * depthWidth + j + nearY[k]];  }  if (k == 25)  depthBuffer3[i * depthWidth + j] /= 25;  else  depthBuffer3[i * depthWidth + j] = depthBuffer2[i * depthWidth + j];  } } \n计算点云坐标\nfor (int i = 0; i \u0026lt; depthHeight; i++) {  for (int j = 0; j \u0026lt; depthWidth; j++)  {  if (depthBuffer3[i * depthWidth + j] == 0)  {  cloudPoints[(i * depthWidth + j) * 3 + 0] = 0;  cloudPoints[(i * depthWidth + j) * 3 + 1] = 0;  cloudPoints[(i * depthWidth + j) * 3 + 2] = 0;  continue;  }  DepthSpacePoint depthSpacePoint;  if (depthHeight == 424)  depthSpacePoint = { static_cast\u0026lt;float\u0026gt;(j), static_cast\u0026lt;float\u0026gt;(i) };  else  depthSpacePoint = { static_cast\u0026lt;float\u0026gt;(i), static_cast\u0026lt;float\u0026gt;(j) };  UINT16 depth = depthBuffer3[i * depthWidth + j];  CameraSpacePoint cameraSpacePoint = { 0.0f, 0.0f, 0.0f };  m_pMap-\u0026gt;MapDepthPointToCameraSpace(depthSpacePoint, depth, \u0026amp;cameraSpacePoint);  if (depthHeight==424)  {  cloudPoints[(i * depthWidth + j) * 3 + 0] = cameraSpacePoint.X;  cloudPoints[(i * depthWidth + j) * 3 + 1] = cameraSpacePoint.Y;  cloudPoints[(i * depthWidth + j) * 3 + 2] = cameraSpacePoint.Z;  }  else  {  cloudPoints[(i * depthWidth + j) * 3 + 0] = cameraSpacePoint.Y;  cloudPoints[(i * depthWidth + j) * 3 + 1] = -cameraSpacePoint.X;  cloudPoints[(i * depthWidth + j) * 3 + 2] = cameraSpacePoint.Z;  }  if (depth \u0026gt;= low \u0026amp;\u0026amp; depth \u0026lt;= high)  depthBuffer2[i * depthWidth + j] = (depthBuffer3[i * depthWidth + j] - low) * 256 / (high - low);  else  depthBuffer2[i * depthWidth + j] = 0;  } } 一维数组cloudPoints：\n   X1 Y1 Z1 X2 Y2 Z2 \u0026hellip; \u0026hellip; \u0026hellip; Xn Yn Zn    根据像素点的下标（i,j）生成depthSpacePoint(x,y)，然后利用depthSpacePoint和深度值depth生成相机空间坐标cameraSpacePoint(x,y,z)\n点云坐标即为相机空间坐标\ncloudPoints[(i * depthWidth + j) * 3 + 0] = cameraSpacePoint.X; cloudPoints[(i * depthWidth + j) * 3 + 1] = cameraSpacePoint.Y; cloudPoints[(i * depthWidth + j) * 3 + 2] = cameraSpacePoint.Z; \n对depthBuffer2进行归一化[0,256]\nif (depth \u0026gt;= low \u0026amp;\u0026amp; depth \u0026lt;= high)  depthBuffer2[i * depthWidth + j] = (depthBuffer3[i * depthWidth + j] - low) * 256 / (high - low); else  depthBuffer2[i * depthWidth + j] = 0; \n遍历每一个像素点，如果其左右两个点的深度为0，就将其坐标置为(0，0，0)\nfor (int i = 1; i \u0026lt; depthHeight-1; i++) {  for (int j = 1; j \u0026lt; depthWidth-1; j++)  {  float z1 = cloudPoints[(i * depthWidth + j) * 3 + 2];  float z2 = cloudPoints[(i * depthWidth + j + 1) * 3 + 2];  float z3 = cloudPoints[(i * depthWidth + j - 1) * 3 + 2];  if (z1 != 0 \u0026amp;\u0026amp; z2 == 0 \u0026amp;\u0026amp; z3 == 0)  {  cloudPoints[(i * depthWidth + j) * 3 + 0] = 0;  cloudPoints[(i * depthWidth + j) * 3 + 1] = 0;  cloudPoints[(i * depthWidth + j) * 3 + 2] = 0;  }  } } \n存储人体所在的区域的数据\nheight为人体高度，weidth为人体宽度，一维数组input2的前四个值为人体的up\\down\\left\\right\n存储至文件”DepthPP_\u0026hellip;\u0026hellip;..“\nint height = down - up + 1; int width = right - left + 1;  UINT16* input2 = new UINT16[height*width + 4](); input2[0] = up; input2[1] = down; input2[2] = left; input2[3] = right; for (int i = 0; i \u0026lt; height; i++) {  for (int j = 0; j \u0026lt; width; j++)  {  int x = left + j;  int y = up + i;  input2[i*width + j + 4] = depthBuffer2[y*depthWidth + x];  } } f5.write(reinterpret_cast\u0026lt;char*\u0026gt;(input2), (height* width + 4) * sizeof(UINT16)); delete[] input2; 同上\n存储至文件”DepthP_\u0026hellip;\u0026hellip;..“\nint height1, height2; if (subId == 1)  height1 = 1, height2 = height; if (subId \u0026gt;= 2)  height1 = 1, height2 = height; down = up + height2 - 1; up = up + height1 - 1; height = height2 - height1 + 1;  UINT16* input = new UINT16[height * width + 4]();  input[0] = up; input[1] = down; input[2] = left; input[3] = right; for (int i = 0; i \u0026lt; height; i++) {  for (int j = 0; j \u0026lt; width; j++)  {  int x = left + j;  int y = up + i;  input[i*width + j + 4] = depthBuffer2[y*depthWidth + x];  } } f4.write(reinterpret_cast\u0026lt;char*\u0026gt;(input), (height* width + 4) * sizeof(UINT16)); \n  outputFile();\n  将点云cloudPoint存储至文件”Cloud_\u0026hellip;\u0026hellip;“\n//输出分割后的点云 void ImageProcess::outputFile() { \tf3.write(reinterpret_cast\u0026lt;char*\u0026gt;(cloudPoints), depthHeight * depthWidth * 3 * sizeof(FLOAT)); }    deepLearning();\n深度学习预测关键点\nvoid ImageProcess::deepLearning() { \tstring fileName; \tQFileInfo file;  \tif (subId == 1) { \tfileName = \u0026#34;DepthPP_\u0026#34; + to_string(fileId) + \u0026#34;_1.dat\u0026#34;; \tfile.setFile(QString::fromStdString(\u0026#34;./Data/DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_1.dat\u0026#34;)); \t} \telse if (subId == 2) { \tfileName = \u0026#34;DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_2.dat\u0026#34;; \tfile.setFile(QString::fromStdString(\u0026#34;./Data/DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_2.dat\u0026#34;)); \t} \telse if (subId == 3){ \tfileName = \u0026#34;DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_3.dat\u0026#34;; \tfile.setFile(QString::fromStdString(\u0026#34;./Data/DepthP_\u0026#34; + to_string(fileId) + \u0026#34;_3.dat\u0026#34;)); \t}  \t//当正面 背面 走路全录入后 一起送进网络进行预测 \tif (file.isFile()) \t{ \tstring mCommand = \u0026#34;predict/predict \u0026#34;; \tmCommand += fileName; \tWinExec(mCommand.c_str(), SW_HIDE); \t} } \n  compressData();\n压缩点云文件\ncompress(buf, \u0026amp;bufLen, cloud, cloudLen)\ncompress是第三方库zlib中压缩数据的函数\n  //压缩点云文件、删除原始深度图像数据、压缩分割后深度图像视频 void ImageProcess::compressData() { \tunsigned long Len; \tif (subId == 3) \tLen = 424 * 512 * 3 * 150 * sizeof(FLOAT); \telse \tLen = 424 * 512 * 3 * sizeof(FLOAT);  \tstring cloudName = \u0026#34;./Data/Cloud_\u0026#34; + to_string(fileId) + \u0026#34;_\u0026#34; + to_string(subId) + \u0026#34;.dat\u0026#34;; \tf2.open(cloudName, ios::binary); \tunsigned char* cloud = new unsigned char[Len]; \tunsigned long cloudLen = Len; \tf2.read(reinterpret_cast\u0026lt;char*\u0026gt;(cloud), cloudLen); \tf2.close(); \tunsigned char* buf = new unsigned char[Len]; \tunsigned long bufLen = Len; \tcompress(buf, \u0026amp;bufLen, cloud, cloudLen); \tf3.open(cloudName, ios::binary); \tf3.write(reinterpret_cast\u0026lt;char*\u0026gt;(buf), bufLen); \tf3.close(); \tdelete[] buf; \tdelete[] cloud; } 显示点云（dataProcess项目） 用PCL渲染点云\n//-------------------------------点云渲染------------------------------------ cloud-\u0026gt;clear(); for (int i = 0; i \u0026lt; dephtHeight; i++) { \tfor (int j = 0; j \u0026lt; depthWidth; j++) \t{ \tif (depthBuffer[i * depthWidth + j] == 0) \t{ \tcloudPoints[(i * depthWidth + j) * 3 + 0] = 0; \tcloudPoints[(i * depthWidth + j) * 3 + 1] = 0; \tcloudPoints[(i * depthWidth + j) * 3 + 2] = 0; \tcontinue; \t} \tfloat cx, cy, cz; \tif (cameraMap-\u0026gt;convertDepthToXYZ(j, i, depthBuffer[i*depthWidth+j], cx, cy, cz))  {  cloudPoints[(i * depthWidth + j) * 3 + 0] = -cx;  cloudPoints[(i * depthWidth + j) * 3 + 1] = cy;  cloudPoints[(i * depthWidth + j) * 3 + 2] = cz;  } \t} } int id = 0; for (int i = 0; i \u0026lt; dephtHeight * depthWidth; i++) {  if (cloudPoints[i * 3 + 0] == 0)  continue;  pcl::PointXYZ p;  p.x = cloudPoints[i * 3 + 0];  p.y = cloudPoints[i * 3 + 1];  p.z = cloudPoints[i * 3 + 2];  cloud-\u0026gt;push_back(p);  centerX += p.x;  centerY += p.y;  centerZ += p.z;  id++; } if (id != 0) {  centerX = centerX / id;  centerY = centerY / id;  centerZ = centerZ / id; } else {  centerX = 0;  centerY = 0;  centerZ = 0; } viewer-\u0026gt;setCameraPosition(0, 0, -2, centerX, centerY, centerZ, 0, 0, 0, 0); viewer-\u0026gt;setBackgroundColor(0, 0, 0, 0); viewer-\u0026gt;removeAllPointClouds(); viewer-\u0026gt;addPointCloud(cloud, \u0026#34;cloud\u0026#34;); ui.body3D-\u0026gt;update(); "
},
{
	"uri": "http://example.org/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]